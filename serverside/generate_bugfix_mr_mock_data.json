{
    "arguments": {
        "args": [],
        "kwargs": {
            "self": {
                "python_type": "<class 'src.utils.integrations.github_integration.RepoHelper'>",
                "json_serialized": "<src.utils.integrations.github_integration.RepoHelper object at 0x7f7174183c10>"
            }
        }
    },
    "return_value": {
        "python_type": "<class 'dict'>",
        "json_serialized": "{\"class\": {\"SerializedObject\": [{\"file_path\": \"serverside/src/server.py\", \"line_start\": 14, \"line_end\": 16, \"content\": \"class SerializedObject(BaseModel):\\n    python_type: str\\n    json_serialized: str\"}], \"Arguments\": [{\"file_path\": \"serverside/src/server.py\", \"line_start\": 19, \"line_end\": 21, \"content\": \"class Arguments(BaseModel):\\n    args: List[Any] = Field(default_factory=list)\\n    kwargs: Dict[str, SerializedObject] = Field(default_factory=dict)\"}], \"ExceptionInfo\": [{\"file_path\": \"serverside/src/server.py\", \"line_start\": 24, \"line_end\": 27, \"content\": \"class ExceptionInfo(BaseModel):\\n    type: str\\n    value: str\\n    traceback: List[str]\"}], \"BaseExecutionTraceItem\": [{\"file_path\": \"serverside/src/server.py\", \"line_start\": 30, \"line_end\": 39, \"content\": \"class BaseExecutionTraceItem(BaseModel):\\n    id: str\\n    timestamp: str\\n    event: str\\n    function: str\\n    caller_id: Optional[str] = None\\n    file: str\\n    line: int\\n    source_line: str\\n    tag: str\"}], \"CallExecutionTraceItem\": [{\"file_path\": \"serverside/src/server.py\", \"line_start\": 42, \"line_end\": 44, \"content\": \"class CallExecutionTraceItem(BaseExecutionTraceItem):\\n    arguments: Arguments\\n    return_value: SerializedObject\"}], \"LineExecutionTraceItem\": [{\"file_path\": \"serverside/src/server.py\", \"line_start\": 47, \"line_end\": 48, \"content\": \"class LineExecutionTraceItem(BaseExecutionTraceItem):\\n    pass\"}], \"ExceptionExecutionTraceItem\": [{\"file_path\": \"serverside/src/server.py\", \"line_start\": 51, \"line_end\": 52, \"content\": \"class ExceptionExecutionTraceItem(BaseExecutionTraceItem):\\n    exception_info: ExceptionInfo\"}], \"ReturnExecutionTraceItem\": [{\"file_path\": \"serverside/src/server.py\", \"line_start\": 55, \"line_end\": 56, \"content\": \"class ReturnExecutionTraceItem(BaseExecutionTraceItem):\\n    return_value: SerializedObject\"}], \"TraceData\": [{\"file_path\": \"serverside/src/server.py\", \"line_start\": 59, \"line_end\": 81, \"content\": \"class TraceData(BaseModel):\\n    invocation_id: str\\n    timestamp: str\\n    endpoint: str\\n    execution_trace: List[Any]\\n    output: Optional[Dict[str, Any]] = None\\n    call_stack: List[Dict[str, Any]] = []\\n    log_filename: Optional[str] = None\\n    input: Dict[str, Any]\\n\\n    @validator(\\\"execution_trace\\\", pre=True)\\n    def parse_execution_trace(cls, v):\\n        items = []\\n        mapping = {\\n            \\\"call\\\": CallExecutionTraceItem,\\n            \\\"line\\\": LineExecutionTraceItem,\\n            \\\"exception\\\": ExceptionExecutionTraceItem,\\n            \\\"return\\\": ReturnExecutionTraceItem,\\n        }\\n        for item in v:\\n            item_type = mapping.get(item.get(\\\"event\\\"), BaseExecutionTraceItem)\\n            items.append(parse_obj_as(item_type, item))\\n        return items\"}], \"Transaction\": [{\"file_path\": \"clientside/examples/fastapi/server.py\", \"line_start\": 15, \"line_end\": 18, \"content\": \"class Transaction(BaseModel):\\n    user_id: str\\n    company_id: str\\n    amount: float\"}], \"Tracer\": [{\"file_path\": \"clientside/src/captureflow/tracer.py\", \"line_start\": 25, \"line_end\": 166, \"content\": \"class Tracer:\\n    def __init__(self, repo_url: str, server_base_url: str = \\\"http://127.0.0.1:8000\\\"):\\n        \\\"\\\"\\\"Initialize the tracer with the repository URL and optionally the remote logging URL.\\\"\\\"\\\"\\n        self.repo_url = repo_url\\n        self.trace_endpoint_url = f\\\"{server_base_url.rstrip('/')}/api/v1/traces\\\"\\n\\n    def trace_endpoint(self, func: Callable) -> Callable:\\n        \\\"\\\"\\\"Decorator to trace endpoint function calls.\\\"\\\"\\\"\\n\\n        # TODO: Give option to specify log \\\"verbosity\\\"\\n        #       Max verbosity                           => need \\\"heavy\\\" sys.settrace()\\n        #           Subgoal: investigate sampling of requests (e.g. log every N-th request) to make it less \\\"heavy\\\"\\n        #       Min verbosity (e.g. only exceptions)    => we could patch Flask/FastAPI methods and that would be better performance wise\\n        @wraps(func)\\n        async def wrapper(*args, **kwargs) -> Any:\\n            try:\\n                invocation_id = str(uuid.uuid4())\\n                context = {\\n                    \\\"invocation_id\\\": invocation_id,\\n                    \\\"timestamp\\\": datetime.now().isoformat(),\\n                    \\\"endpoint\\\": func.__qualname__,\\n                    \\\"input\\\": {\\n                        \\\"args\\\": [self._serialize_variable(arg) for arg in args],\\n                        \\\"kwargs\\\": {k: self._serialize_variable(v) for k, v in kwargs.items()},\\n                    },\\n                    \\\"execution_trace\\\": [],\\n                    \\\"log_filename\\\": f\\\"{TEMP_FOLDER}{func.__name__}_trace_{invocation_id}.json\\\",\\n                }\\n\\n                sys.settrace(self._setup_trace(context))\\n                result = await func(*args, **kwargs) if asyncio.iscoroutinefunction(func) else func(*args, **kwargs)\\n                context[\\\"output\\\"] = {\\\"result\\\": self._serialize_variable(result)}\\n            finally:\\n                sys.settrace(None)\\n                self._send_trace_log(context)\\n\\n            return result\\n\\n        return wrapper\\n\\n    def _send_trace_log(self, context: Dict[str, Any]) -> None:\\n        if os.environ.get(\\\"CAPTUREFLOW_DEV_SERVER\\\") == \\\"true\\\":\\n            log_filename = f\\\"trace_{context['invocation_id']}.json\\\"\\n            with open(log_filename, \\\"w\\\") as f:\\n                json.dump(context, f, indent=4)\\n\\n        try:\\n            response = requests.post(\\n                self.trace_endpoint_url,\\n                params={\\\"repository-url\\\": self.repo_url},  # TODO: move param to HTTP body\\n                json=context,\\n                headers={\\\"Content-Type\\\": \\\"application/json\\\"},\\n            )\\n            if response.status_code != 200:\\n                logger.info(f\\\"CaptureFlow server responded: {response.status_code}\\\")\\n        except Exception as e:\\n            logger.info(f\\\"Exception during logging: {e}\\\")\\n\\n    def _serialize_variable(self, value: Any) -> Dict[str, Any]:\\n        try:\\n            json_value = json.dumps(value)\\n        except Exception as e:\\n            try:\\n                json_value = str(value)  # If the value cannot be serialized to JSON, use str() / repr()\\n            except Exception as e:\\n                json_value = \\\"<unrepresentable object>\\\"  # Very rare case, but can happen with e.g. MagicMocks\\n                logger.info(f\\\"Failed to convert variable to string. Type: {type(value)}, Error: {e}\\\")\\n\\n        return {\\\"python_type\\\": str(type(value)), \\\"json_serialized\\\": json_value}\\n\\n    def _get_file_tag(self, file_path: str) -> str:\\n        \\\"\\\"\\\"Determine the file tag based on the file path.\\\"\\\"\\\"\\n        if STDLIB_PATH in file_path:\\n            return \\\"STDLIB\\\"\\n        elif LIBRARY_PATH in file_path:\\n            return \\\"LIBRARY\\\"\\n        return \\\"INTERNAL\\\"\\n\\n    def _setup_trace(self, context: Dict[str, Any]) -> Callable:\\n        \\\"\\\"\\\"Setup the trace function.\\\"\\\"\\\"\\n        context[\\\"call_stack\\\"] = []\\n        return lambda frame, event, arg: self._trace_function_calls(frame, event, arg, context)\\n\\n    def _capture_arguments(self, frame) -> Dict[str, Any]:\\n        \\\"\\\"\\\"\\n        Capture arguments passed to the function and serialize them.\\n        This simplified version does not distinguish between args and kwargs based on the function's signature.\\n        \\\"\\\"\\\"\\n        args, _, _, values = inspect.getargvalues(frame)\\n\\n        serialized_args = []\\n        serialized_kwargs = {}\\n        for arg in args:\\n            serialized_value = self._serialize_variable(values[arg])\\n            if arg == \\\"args\\\" or arg.startswith(\\\"arg\\\"):\\n                serialized_args.append(serialized_value)\\n            else:\\n                serialized_kwargs[arg] = serialized_value\\n\\n        return {\\\"args\\\": serialized_args, \\\"kwargs\\\": serialized_kwargs}\\n\\n    def _trace_function_calls(self, frame, event, arg, context: Dict[str, Any]) -> Callable:\\n        \\\"\\\"\\\"Trace function calls and capture relevant data.\\\"\\\"\\\"\\n        code = frame.f_code\\n        func_name, file_name, line_no = code.co_name, code.co_filename, frame.f_lineno\\n\\n        tag = self._get_file_tag(file_name)\\n        caller_id = context[\\\"call_stack\\\"][-1][\\\"id\\\"] if context[\\\"call_stack\\\"] else None\\n\\n        call_id = str(uuid.uuid4())\\n        trace_event = {\\n            \\\"id\\\": call_id,\\n            \\\"timestamp\\\": datetime.now().isoformat(),\\n            \\\"event\\\": event,\\n            \\\"function\\\": func_name,\\n            \\\"caller_id\\\": caller_id,\\n            \\\"file\\\": file_name,\\n            \\\"line\\\": line_no,\\n            \\\"source_line\\\": linecache.getline(file_name, line_no).strip(),\\n            \\\"tag\\\": tag,\\n        }\\n\\n        if event == \\\"call\\\":\\n            trace_event[\\\"arguments\\\"] = self._capture_arguments(frame)\\n            context[\\\"call_stack\\\"].append(trace_event)\\n        elif event == \\\"return\\\":\\n            trace_event[\\\"return_value\\\"] = self._serialize_variable(arg)\\n            # Also update \\\"call\\\" frame, because it's quick\\n            if context[\\\"call_stack\\\"]:\\n                context[\\\"call_stack\\\"][-1][\\\"return_value\\\"] = self._serialize_variable(arg)\\n                context[\\\"call_stack\\\"].pop()\\n        elif event == \\\"exception\\\":\\n            exc_type, exc_value, exc_traceback = arg\\n            trace_event[\\\"exception_info\\\"] = {\\n                \\\"type\\\": str(exc_type.__name__),\\n                \\\"value\\\": str(exc_value),\\n                \\\"traceback\\\": traceback.format_tb(exc_traceback),\\n            }\\n\\n        context[\\\"execution_trace\\\"].append(trace_event)\\n\\n        return lambda frame, event, arg: self._trace_function_calls(frame, event, arg, context)\"}], \"CallGraph\": [{\"file_path\": \"serverside/src/utils/call_graph.py\", \"line_start\": 10, \"line_end\": 104, \"content\": \"class CallGraph:\\n    def __init__(self, log_data: str):\\n        self.graph = nx.DiGraph()\\n        self._build_graph(log_data)\\n\\n    def _build_graph(self, log_data: str) -> None:\\n        data = json.loads(log_data) if isinstance(log_data, str) else log_data\\n        # Track nodes that threw exceptions\\n        exception_nodes = {}\\n\\n        for event in data[\\\"execution_trace\\\"]:\\n            if event[\\\"event\\\"] in [\\\"call\\\", \\\"exception\\\"]:\\n                if event[\\\"event\\\"] == \\\"call\\\":\\n                    node_attrs = {\\n                        \\\"function\\\": event[\\\"function\\\"],\\n                        \\\"file_line\\\": f\\\"{event['file']}:{event['line']}\\\",\\n                        \\\"tag\\\": event.get(\\\"tag\\\", \\\"INTERNAL\\\"),\\n                        \\\"arguments\\\": event.get(\\\"arguments\\\", {}),\\n                        \\\"return_value\\\": event.get(\\\"return_value\\\", {}),\\n                        \\\"exception\\\": False,  # Initialize nodes with no exception\\n                    }\\n                elif event[\\\"event\\\"] == \\\"exception\\\":\\n                    # Update the caller node with exception info\\n                    caller_node = self.graph.nodes[event[\\\"caller_id\\\"]]\\n                    caller_node[\\\"did_raise\\\"] = True\\n                    caller_node[\\\"unhandled_exception\\\"] = {\\n                        \\\"type\\\": event[\\\"exception_info\\\"][\\\"type\\\"],\\n                        \\\"value\\\": event[\\\"exception_info\\\"][\\\"value\\\"],\\n                        \\\"traceback\\\": event[\\\"exception_info\\\"][\\\"traceback\\\"],\\n                    }\\n\\n                    continue\\n\\n                self.graph.add_node(event[\\\"id\\\"], **node_attrs)\\n\\n                # Add an edge from the caller to the current function call\\n                caller_id = event.get(\\\"caller_id\\\")\\n                if caller_id and caller_id in self.graph:\\n                    self.graph.add_edge(caller_id, event[\\\"id\\\"])\\n\\n                # If the caller had an exception, link this event as part of the exception chain\\n                if caller_id in exception_nodes:\\n                    self.graph.add_edge(exception_nodes[caller_id], event[\\\"id\\\"])\\n\\n    def iterate_graph(self) -> None:\\n        \\\"\\\"\\\"Iterates through the graph, printing details of each node and its successors.\\\"\\\"\\\"\\n        for node, attrs in self.graph.nodes(data=True):\\n            function_name = attrs[\\\"function\\\"]\\n            file_line = attrs[\\\"file_line\\\"]\\n            tag = attrs[\\\"tag\\\"]\\n            successors = \\\", \\\".join(self.graph.nodes[succ][\\\"function\\\"] for succ in self.graph.successors(node))\\n            logging.info(f\\\"Function: {function_name} ({file_line}, {tag}) -> {successors or 'No outgoing calls'}\\\")\\n\\n    def export_for_graphviz(self) -> None:\\n        \\\"\\\"\\\"Exports the graph in a format compatible with Graphviz.\\\"\\\"\\\"\\n        nodes = [(node, self.graph.nodes[node]) for node in self.graph.nodes()]\\n        edges = list(self.graph.edges())\\n        return nodes, edges\\n\\n    def find_node_by_fname(self, function_name: str) -> list[any]:\\n        \\\"\\\"\\\"Finds nodes that correspond to a given function name.\\\"\\\"\\\"\\n        matching_nodes = []\\n        for node, attrs in self.graph.nodes(data=True):\\n            if attrs[\\\"function\\\"] == function_name:\\n                matching_nodes.append(node)\\n        return matching_nodes\\n\\n    def draw(self, output_filename=\\\"func_call_graph\\\"):\\n        from graphviz import Digraph\\n\\n        dot = Digraph(comment=\\\"Function Call Graph\\\")\\n        color_mapping = {\\\"STDLIB\\\": \\\"gray\\\", \\\"LIBRARY\\\": \\\"blue\\\", \\\"INTERNAL\\\": \\\"white\\\"}\\n\\n        nodes = [(node, self.graph.nodes[node]) for node in self.graph.nodes()]\\n        edges = list(self.graph.edges())\\n\\n        for node, attrs in nodes:\\n            tag = attrs[\\\"tag\\\"]\\n            node_color = color_mapping.get(\\\"EXCEPTION\\\" if attrs[\\\"exception\\\"] else tag, \\\"white\\\")\\n\\n            label_parts = [\\n                f\\\"Function: {attrs['function']}\\\",\\n                f\\\"Tag: {tag}\\\",\\n                f\\\"Arguments: {json.dumps(attrs.get('arguments', {}), indent=2)}\\\",\\n                f\\\"Returns: {json.dumps(attrs.get('return_value', {}), indent=2)}\\\",\\n                f\\\"Did Raise: {attrs.get('did_raise', {})}\\\",\\n                f\\\"Traceback: {attrs.get('unhandled_exception', {})}\\\",\\n            ]\\n\\n            dot.node(node, label=\\\"\\\\n\\\".join(label_parts), style=\\\"filled\\\", fillcolor=node_color)\\n\\n        for u, v in edges:\\n            dot.edge(u, v)\\n\\n        dot.render(output_filename, view=True)\"}], \"TestCoverageItem\": [{\"file_path\": \"serverside/src/utils/docker_executor.py\", \"line_start\": 19, \"line_end\": 21, \"content\": \"class TestCoverageItem:\\n    coverage: float\\n    missing_lines: list[int]\"}], \"PytestOutput\": [{\"file_path\": \"serverside/src/utils/docker_executor.py\", \"line_start\": 27, \"line_end\": 30, \"content\": \"class PytestOutput:\\n    def __init__(self, test_coverage: dict[Path, TestCoverageItem], pytest_raw_output: str):\\n        self.test_coverage = test_coverage\\n        self.pytest_raw_output = pytest_raw_output\"}], \"DockerExecutor\": [{\"file_path\": \"serverside/src/utils/docker_executor.py\", \"line_start\": 33, \"line_end\": 125, \"content\": \"class DockerExecutor:\\n    SPLIT_TOKEN = \\\"====SPLIT=====\\\"\\n\\n    def __init__(self, repo_url):\\n        \\\"\\\"\\\"\\n        User repo will have .captureflow['run-tests']\\n        \\\"\\\"\\\"\\n        self.repo_url = repo_url\\n        self.repo_helper = RepoHelper(repo_url=self.repo_url)\\n\\n    def _generate_jwt(self, app_id, private_key):\\n        payload = {\\n            \\\"iat\\\": int(time.time()) - 60,  # Issued at time\\n            \\\"exp\\\": int(time.time()) + 600,  # JWT expiration time\\n            \\\"iss\\\": app_id,\\n        }\\n        token = jwt.encode(payload, private_key, algorithm=\\\"RS256\\\")\\n        return token\\n\\n    def _get_installation_access_token(self, installation_id, jwt):\\n        headers = {\\\"Authorization\\\": f\\\"Bearer {jwt}\\\", \\\"Accept\\\": \\\"application/vnd.github.v3+json\\\"}\\n        url = f\\\"https://api.github.com/app/installations/{installation_id}/access_tokens\\\"\\n        response = requests.post(url, headers=headers)\\n        return response.json()[\\\"token\\\"]\\n\\n    def _clone_repository(self, repo_url: str, access_token: str, output_path: Path):\\n        # Modify the repo URL to include the access token\\n        auth_repo_url = repo_url.replace(\\\"https://\\\", f\\\"https://x-access-token:{access_token}@\\\")\\n        cmd = f\\\"git clone {auth_repo_url} {output_path}\\\"\\n        logging.info(f\\\"Running command: {cmd}\\\")\\n        subprocess.run(cmd.split(\\\" \\\"))\\n\\n    def _build_container(self, tag: str, repo_path: Path):\\n        cmd = f'docker build -f {repo_path / \\\"Dockerfile.cf\\\"} -t {tag} {repo_path}'\\n        logging.info(f\\\"Running cmd: {cmd}\\\")\\n        subprocess.run(cmd.split(\\\" \\\"))\\n\\n    def _run_tests_and_get_coverage(self, tag: str) -> PytestOutput:\\n        # TODO: It's temporary fix, will think about it later.\\n        cmd = f'docker run -t {tag} /bin/bash -c \\\"cd serverside && pytest --cov=. --cov-report json >pytest_output; cat coverage.json; echo \\\"{self.SPLIT_TOKEN}\\\"; cat pytest_output;\\\"'\\n        logging.info(f\\\"Running cmd: {cmd}\\\")\\n        proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, shell=True)\\n\\n        cmd_output = proc.stdout.read().decode(\\\"utf-8\\\")\\n        coverage_output, pytest_raw_output = cmd_output.split(self.SPLIT_TOKEN)\\n        coverage_output = json.loads(coverage_output)\\n\\n        # TODO: This is temporary solution for testing.\\n        test_coverage = {\\n            f\\\"serverside/{key}\\\": TestCoverageItem(\\n                coverage=float(info_dict[\\\"summary\\\"][\\\"percent_covered\\\"]), missing_lines=list(info_dict[\\\"missing_lines\\\"])\\n            )\\n            for key, info_dict in coverage_output[\\\"files\\\"].items()\\n        }\\n\\n        return PytestOutput(test_coverage=test_coverage, pytest_raw_output=pytest_raw_output)\\n\\n    def _create_files(self, repo_dir: Path, new_files: dict[str, str]):\\n        for file_path, contents in new_files.items():\\n            # TODO: This is done temporarily, will change it later to properly copy it to docker.\\n            with open(repo_dir / file_path, \\\"w\\\") as f:\\n                logging.info(f\\\"Creating new file at: {repo_dir / file_path}\\\")\\n                f.write(contents)\\n\\n    def execute_with_new_files(self, new_files: dict[str, str]) -> PytestOutput:\\n        \\\"\\\"\\\"\\n        new_files:\\n            {\\n                '/path/to/new/test_1': 'def test_blah():\\\\n  return True',\\n                '/path/to/new/test_2': 'def test_blah2():\\\\n  return True',\\n            }\\n\\n        gh_repo.clone_repo()\\n        run tests from command with coverage\\n        return PytestOutput\\n        \\\"\\\"\\\"\\n        APP_ID = GITHUB_APP_ID\\n        PRIVATE_KEY = base64.b64decode(GITHUB_APP_PRIVATE_KEY_BASE64).decode(\\\"utf-8\\\")\\n        installation = self.repo_helper.get_installation_by_url(self.repo_url)\\n\\n        jwt_key = self._generate_jwt(APP_ID, PRIVATE_KEY)\\n        access_token = self._get_installation_access_token(installation.id, jwt_key)\\n\\n        with tempfile.TemporaryDirectory(dir=Path.cwd()) as repo_dir:\\n            logging.info(f\\\"Created temporary directory to clone repo: {repo_dir}\\\")\\n            self._clone_repository(self.repo_url, access_token, output_path=repo_dir)\\n            if len(new_files) > 0:\\n                self._create_files(Path(repo_dir), new_files)\\n            tag = str(uuid4()).split(\\\"-\\\")[0]\\n            self._build_container(tag=tag, repo_path=Path(repo_dir))\\n\\n            pytest_output = self._run_tests_and_get_coverage(tag=tag)\\n            return pytest_output\"}], \"ExceptionPatcher\": [{\"file_path\": \"serverside/src/utils/exception_patcher.py\", \"line_start\": 15, \"line_end\": 343, \"content\": \"class ExceptionPatcher:\\n    def __init__(self, redis_client: Redis, repo_url: str):\\n        self.redis_client = redis_client\\n        self.repo_url = repo_url\\n        self.repo_helper = RepoHelper(repo_url)\\n        self.gpt_helper = OpenAIHelper()\\n\\n    def run(self):\\n        graphs = self.build_graphs_from_redis()\\n        self.enrich_graphs_with_github_context(graphs)\\n\\n        # Here we need to fetch top-level exception node details\\n        #   + all nodes that also propagated the exception\\n        #       + input_values\\n        #   + N parent node levels for context\\n        #       + input_valuess\\n        #   + M child node levels for context\\n        #       + input_values\\n        for graph in graphs:\\n            exception_chains = self.select_exception_sequences(graph)\\n\\n            if not exception_chains:\\n                logger.info(\\\"No exception chains found in this graph.\\\")\\n                continue\\n            else:\\n                logger.info(f\\\"Found a graph that contained unhandled exception chain {exception_chains}\\\")\\n\\n            for exception_chain in exception_chains:\\n\\n                context = self.fetch_exception_context(graph, exception_chain)\\n\\n                prompt = self.generate_fix_prompt_based_on_context(context)\\n                gpt_response = self.gpt_helper.call_chatgpt(prompt)\\n\\n                try:\\n                    json_str = self.extract_json_simple(gpt_response)\\n                    if json_str:\\n                        gpt_response_dict = json.loads(json_str)\\n                        change_reasoning = gpt_response_dict.get(\\\"change_reasoning\\\", \\\"\\\")\\n                        function_name = gpt_response_dict.get(\\\"function_name\\\", \\\"\\\")\\n                        code_block = self.gpt_helper.extract_first_code_block(gpt_response)\\n\\n                        matched_node_ids = graph.find_node_by_fname(function_name)\\n                        if matched_node_ids:\\n                            matches_node_id = matched_node_ids[0]\\n\\n                            self.repo_helper.create_pull_request_with_new_function(\\n                                graph.graph.nodes[matches_node_id],\\n                                context,\\n                                code_block,\\n                                change_reasoning,\\n                                self.gpt_helper,\\n                            )\\n                    else:\\n                        logger.error(\\\"Failed to extract JSON from GPT response.\\\")\\n                except (json.JSONDecodeError, KeyError) as e:\\n                    logger.exception(f\\\"Error processing GPT response: {e}\\\")\\n\\n    def extract_json_simple(self, text):\\n        try:\\n            start_index, end_index = text.index(\\\"{\\\"), text.rindex(\\\"}\\\") + 1\\n            json_str = text[start_index:end_index]\\n            return json_str\\n        except ValueError:\\n            return None\\n\\n    def build_graphs_from_redis(self) -> List[CallGraph]:\\n        graphs = []\\n        search_pattern = f\\\"{self.repo_url}:*\\\"\\n        for key in self.redis_client.scan_iter(match=search_pattern):\\n            log_data_json = self.redis_client.get(key)\\n            if log_data_json:\\n                log_data = json.loads(log_data_json.decode(\\\"utf-8\\\"))\\n                graphs.append(CallGraph(json.dumps(log_data)))\\n        return graphs\\n\\n    def enrich_graphs_with_github_context(self, graphs: List[CallGraph]):\\n        for graph in graphs:\\n            self.repo_helper.enrich_callgraph_with_github_context(graph)\\n\\n    def select_exception_sequences(self, graph: CallGraph) -> List[List[str]]:\\n        \\\"\\\"\\\"\\n        Collects sequences of nodes involved in the propagation of the same exception type.\\n        It identifies nodes where exceptions were raised and follows the propagation path \\n        through adjacent nodes sharing the same exception type, forming sequences.\\n\\n        Example:\\n            Consider a function call graph where arrows indicate the call direction, and nodes are labeled \\n            with their function names. Nodes with exceptions have an asterisk (*) next to them, \\n            and the exception type is indicated in brackets.\\n\\n                      a\\n                      |\\n                      b* [Exception X]\\n                    /   \\\\\\n                    c    d* [Exception X]\\n                    |\\n                    e\\n\\n            The exception chain we want to extract is [b*, d*]\\n\\n        Args:\\n            graph (CallGraph): The graph containing nodes with exception information.\\n\\n        Returns:\\n            List[List[str]]: Lists of node ID sequences. Each list represents a chain of\\n                            exception propagation for a specific exception type within the graph.\\n        \\\"\\\"\\\"\\n        exception_sequences = []\\n\\n        # Identify nodes where exceptions were raised.\\n        raised_exception_nodes = [\\n            (node_id, data) for node_id, data in graph.graph.nodes(data=True) if data.get(\\\"did_raise\\\")\\n        ]\\n        visited = set()\\n\\n        for start_node, start_data in raised_exception_nodes:\\n            if start_node in visited:\\n                continue\\n\\n            current_sequence = [start_node]\\n            visited.add(start_node)\\n\\n            # Adjacent nodes with same exception_type => part of same exception propagation chain\\n            start_exception_type = start_data[\\\"unhandled_exception\\\"][\\\"type\\\"]\\n\\n            for neighbor in list(graph.graph.predecessors(start_node)) + list(graph.graph.successors(start_node)):\\n                if neighbor in visited:\\n                    continue\\n\\n                neighbor_data = graph.graph.nodes[neighbor]\\n                if (\\n                    neighbor_data.get(\\\"did_raise\\\")\\n                    and neighbor_data[\\\"unhandled_exception\\\"][\\\"type\\\"] == start_exception_type\\n                ):\\n                    current_sequence.append(neighbor)\\n                    visited.add(neighbor)\\n\\n            # There are quite a lot if internal (invisible) exception chains happening inside libraries\\n            # There is no point in refactoring them => prune and skip if needed\\n            pruned_sequence = [node for node in current_sequence if graph.graph.nodes[node].get(\\\"tag\\\") != \\\"STDLIB\\\"]\\n            if len(pruned_sequence) >= 1:\\n                exception_sequences.append(current_sequence)\\n\\n        return exception_sequences\\n\\n    def fetch_exception_context(self, graph: CallGraph, exception_chain: List[str]) -> Dict[str, Any]:\\n        \\\"\\\"\\\"\\n        Gathers contextual information for nodes involved in exception propagation, including details\\n        about the exception nodes, and any relevant context from non-exceptional ancestors and descendants.\\n\\n        Example:\\n            Given an exception propagating from 'b' to 'd' in the following call graph:\\n\\n                          a\\n                          |\\n                          b* [Exception X]\\n                        /   \\\\\\n                       c     d* [Exception X]\\n                       |\\n                       e\\n\\n            This method provides detailed context for the exception chain ['b*', 'd*'], \\n            and includes information about 'a', 'c' for a comprehensive view.\\n\\n        Args:\\n            graph (CallGraph): The call graph object containing nodes, function calls, and exception information.\\n            exception_chain (List[str]): A list of node IDs representing the sequence of exception propagation.\\n\\n        Returns:\\n            Dict[str, Any]: A dictionary with detailed context about each node in the exception chain,\\n                            including the node's details, immediate non-exceptional ancestors, and descendants.\\n                            This provides a holistic view of the functions leading to and affected by the exception.\\n        \\\"\\\"\\\"\\n        chain_context = {\\\"exception_nodes\\\": []}\\n\\n        for node_id in exception_chain:\\n            node_data = graph.graph.nodes[node_id]\\n            node_context = {\\n                \\\"node_details\\\": self.format_node_details(node_data, include_code=True),\\n                \\\"context_parents\\\": [],\\n                \\\"context_children\\\": [],\\n            }\\n\\n            # Add parents only if they are not part of the exception chain\\n            for parent_id in graph.graph.predecessors(node_id):\\n                if parent_id not in exception_chain:\\n                    parent_data = graph.graph.nodes[parent_id]\\n                    node_context[\\\"context_parents\\\"].append(self.format_node_details(parent_data, include_code=True))\\n\\n            # Add any children called by this node that are not part of the exception chain\\n            for child_id in graph.graph.successors(node_id):\\n                if child_id not in exception_chain:\\n                    child_data = graph.graph.nodes[child_id]\\n                    node_context[\\\"context_children\\\"].append(self.format_node_details(child_data, include_code=True))\\n\\n            chain_context[\\\"exception_nodes\\\"].append(node_context)\\n\\n        return chain_context\\n\\n    def format_node_details(self, node_data: Dict[str, Any], include_code: bool = False) -> Dict[str, Any]:\\n        \\\"\\\"\\\"\\n        Prepares detailed information of a node for further analysis.\\n\\n        This method differentiates between nodes that ended with an exception and those that\\n        completed execution normally, providing either exception details or return values accordingly.\\n\\n        Example output structure:\\n            {\\n                \\\"function_name\\\": \\\"example_function\\\",\\n                \\\"file_line\\\": \\\"example.py:42\\\",\\n                \\\"arguments\\\": {\\\"arg1\\\": \\\"value1\\\", \\\"arg2\\\": \\\"value2\\\"},\\n                \\\"exception_info\\\": {\\\"type\\\": \\\"ValueError\\\", \\\"value\\\": \\\"An error occurred\\\"},\\n                \\\"function_implementation\\\": \\\"def example_function(arg1, arg2): pass\\\",\\n                \\\"file_content\\\": \\\"def example_function(arg1, arg2): pass\\\\n...\\\"\\n            }\\n        \\\"\\\"\\\"\\n        details = {\\n            \\\"function_name\\\": node_data.get(\\\"function\\\"),\\n            \\\"file_line\\\": node_data.get(\\\"file_line\\\", \\\"unknown\\\"),\\n            \\\"arguments\\\": node_data.get(\\\"arguments\\\", {}),\\n            \\\"exception_info\\\": node_data.get(\\\"unhandled_exception\\\"),\\n            \\\"return_value\\\": node_data.get(\\\"return_value\\\"),\\n            \\\"function_implementation\\\": (\\n                node_data.get(\\\"github_function_implementation\\\").get(\\\"content\\\", \\\"Not available\\\")\\n                if isinstance(node_data.get(\\\"github_function_implementation\\\"), dict) and include_code\\n                else \\\"Not available\\\"\\n            ),\\n            \\\"file_content\\\": node_data.get(\\\"github_file_content\\\", \\\"Not available\\\") if include_code else None,\\n        }\\n\\n        # Clean up None values\\n        return {key: value for key, value in details.items() if value is not None}\\n\\n    def fetch_parents(\\n        self, graph: CallGraph, node_id: str, depth: int, include_code: bool = False\\n    ) -> List[Dict[str, Any]]:\\n        \\\"\\\"\\\"\\n        Recursively fetches parent nodes up to a certain depth, including their code.\\n        \\\"\\\"\\\"\\n        if depth == 0:\\n            return []\\n        parents = []\\n        for predecessor in graph.graph.predecessors(node_id):\\n            parent_data = graph.graph.nodes[predecessor]\\n            parents.append(self.format_node_details(parent_data, include_code))\\n            parents.extend(self.fetch_parents(graph, predecessor, depth - 1, include_code))\\n        return parents\\n\\n    def fetch_children(\\n        self, graph: CallGraph, node_id: str, depth: int, include_code: bool = False\\n    ) -> List[Dict[str, Any]]:\\n        \\\"\\\"\\\"\\n        Recursively fetches child nodes up to a certain depth, including their code.\\n        \\\"\\\"\\\"\\n        if depth == 0:\\n            return []\\n        children = []\\n        for successor in graph.graph.successors(node_id):\\n            child_data = graph.graph.nodes[successor]\\n            children.append(self.format_node_details(child_data, include_code))\\n            children.extend(self.fetch_children(graph, successor, depth - 1, include_code))\\n        return children\\n\\n    def generate_fix_prompt_based_on_context(self, context: Dict[str, Any]) -> str:\\n        exception_chain_details = \\\"Exception Chain Analysis:\\\\nBelow is the sequence of functions leading to and including the exception, along with their inputs, outputs, and implementation details:\\\\n\\\"\\n\\n        for index, node_context in enumerate(context[\\\"exception_nodes\\\"]):\\n            node_details = node_context[\\\"node_details\\\"]\\n            is_last_node = index == len(context[\\\"exception_nodes\\\"]) - 1\\n\\n            function_header = (\\n                f\\\"\\\\n{'-'*20}\\\\nFunction: {node_details['function_name']} at {node_details['file_line']}\\\\n{'-'*20}\\\"\\n            )\\n            exception_info = (\\n                f\\\"Exception Type: {node_details['exception_info']['type']} - {node_details['exception_info']['value']}\\\"\\n            )\\n            inputs = f\\\"Inputs (serialization method described at the end):\\\\n{json.dumps(node_details['arguments'], indent=2, default=str)}\\\"\\n            outputs = (\\n                f\\\"Outputs:\\\\n{json.dumps(node_details.get('return_value', 'No return value'), indent=2, default=str)}\\\"\\n            )\\n            implementation = f\\\"Function Implementation:\\\\n```python\\\\n{node_details['function_implementation']}\\\\n```\\\"\\n\\n            node_summary = f\\\"{function_header}\\\\n{exception_info}\\\\n{inputs}\\\\n{outputs}\\\\n{implementation}\\\"\\n\\n            if is_last_node:\\n                node_summary += \\\"\\\\n(This function is where the exception was raised and propagated.)\\\"\\n\\n            additional_context_summary = \\\"\\\"\\n            if node_context[\\\"context_children\\\"]:\\n                additional_context_summary = \\\"\\\\nAdditional context from called functions:\\\\n\\\" + \\\"\\\\n\\\".join(\\n                    f\\\"- {child['function_name']} at {child['file_line']}:\\\\n  Inputs: {json.dumps(child['arguments'], indent=2, default=str)}\\\\n  Outputs: {json.dumps(child.get('return_value', 'No return value'), indent=2, default=str)}\\\\n  Implementation snippet:\\\\n```python\\\\n{child['function_implementation']}\\\\n```\\\"\\n                    for child in node_context[\\\"context_children\\\"]\\n                )\\n\\n            exception_chain_details += f\\\"{node_summary}{additional_context_summary}\\\\n\\\"\\n\\n        serialization_method_description = \\\"\\\"\\\"\\n            Serialization method for input/output values:\\n            ```python\\n            def _serialize_variable(self, value: Any) -> Dict[str, Any]:\\n                try:\\n                    json_value = json.dumps(value)\\n                except Exception as e:\\n                    json_value = str(value)\\n                return {\\\"python_type\\\": str(type(value)), \\\"json_serialized\\\": json_value}\\n            ```\\n        \\\"\\\"\\\"\\n\\n        formatting_commands = \\\"\\\"\\\"\\n            Please provide me two things: JSON of this form\\n            1. \\\"confidence\\\" that new code is going to resolve such exceptions (1 to 5)\\n            2. \\\"function_name\\\" that best to be updated to resolve exception.\\n            3. \\\"change_reasoning\\\" why do you think change is going to address exception.\\n            and new proposed function code right escaped with ```python ...``` after it.\\n            Here's example output:\\n            {\\n                \\\"confidence\\\": 5,\\n                \\\"function_name\\\": \\\"do_stuff\\\",\\n                \\\"change_reasoning\\\": \\\"to fix above exception the most correct thing is ...\\\"\\n            }\\n            ```python\\n            def do_stuff():\\n                pass # new implementation\\n            ```\\n        \\\"\\\"\\\"\\n\\n        prompt = f\\\"{exception_chain_details}\\\\n{serialization_method_description}\\\\n{formatting_commands}\\\"\\n        return prompt\"}], \"TestCoverageCreator\": [{\"file_path\": \"serverside/src/utils/test_creator.py\", \"line_start\": 16, \"line_end\": 177, \"content\": \"class TestCoverageCreator:\\n    def __init__(self, redis_client: Redis, repo_url: str):\\n        self.redis_client = redis_client\\n        self.repo_url = repo_url\\n        self.gpt_helper = OpenAIHelper()\\n        self.repo_helper = RepoHelper(repo_url)\\n\\n    def run(self):\\n        graphs = self.build_graphs_from_redis()\\n        for graph in graphs:\\n            self.repo_helper.enrich_callgraph_with_github_context(graph)\\n            entry_point_node_id = self.select_function_to_cover(graph)\\n            if entry_point_node_id is None:\\n                logger.info(\\\"No entry point function was selected for coverage.\\\")\\n                continue\\n\\n            all_interactions = []  # Stores GPT-friendly info regarding what interactions are likely external (DBs/APIs)\\n            function_context = (\\n                []\\n            )  # Stores GPT-friendly info regarding what CallGraph nodes are doing (implementation, filename, etc)\\n            self.analyze_graph_for_interactions_and_context(\\n                graph, entry_point_node_id, all_interactions, function_context\\n            )\\n\\n            test_prompt = self.generate_test_prompt(function_context, all_interactions, graph, entry_point_node_id)\\n            gpt_response = self.gpt_helper.call_chatgpt(test_prompt)\\n            pytest_full_code = self.gpt_helper.extract_first_code_block(gpt_response)\\n\\n            if pytest_full_code:\\n                logger.info(\\n                    f\\\"Generated full pytest code for {graph.graph.nodes[entry_point_node_id]['function']}:\\\\n{pytest_full_code}\\\"\\n                )\\n                test_file_name = f\\\"captureflow_tests/test_{graph.graph.nodes[entry_point_node_id]['function'].replace(' ', '_').lower()}.py\\\"\\n                self.repo_helper.create_pull_request_with_test(\\n                    test_file_name, pytest_full_code, graph.graph.nodes[entry_point_node_id][\\\"function\\\"]\\n                )\\n            else:\\n                logger.error(\\\"Failed to generate valid full pytest code.\\\")\\n\\n    def build_graphs_from_redis(self) -> List[CallGraph]:\\n        graphs = []\\n        search_pattern = f\\\"{self.repo_url}:*\\\"\\n        for key in self.redis_client.scan_iter(match=search_pattern):\\n            log_data_json = self.redis_client.get(key)\\n            if log_data_json:\\n                log_data = json.loads(log_data_json.decode(\\\"utf-8\\\"))\\n                graphs.append(CallGraph(json.dumps(log_data)))\\n        return graphs\\n\\n    def select_function_to_cover(self, graph: CallGraph) -> Optional[str]:\\n        # Select the first non-stdlib node as the entry point for testing.\\n        # TODO: Replace with a way to get endpoint\\n        for node_id, data in graph.graph.nodes(data=True):\\n            if data.get(\\\"tag\\\") != \\\"STDLIB\\\":\\n                return node_id\\n        return None\\n\\n    def analyze_external_interactions_with_chatgpt(self, node_data: Dict[str, Any]) -> List[Dict[str, Any]]:\\n        function_implementation = node_data.get(\\\"github_function_implementation\\\", {}).get(\\\"content\\\", \\\"Not available\\\")\\n        json_example = {\\n            \\\"interactions\\\": [\\n                {\\n                    \\\"type\\\": \\\"DB_INTERACTION | API_CALL\\\",\\n                    \\\"details\\\": \\\"Query to SQLite database for user data at line 14\\\",\\n                    \\\"mock_idea\\\": 'with patch(\\\"sqlite3.connect\\\") as mock_connect: mock_cursor = mock_connect.return_value.cursor.return_value; mock_cursor.fetchall.return_value = [(10,), (20,)]',\\n                    \\\"certainty\\\": \\\"high\\\",\\n                }\\n            ]\\n        }\\n        prompt = (\\n            f\\\"Please analyze the provided Python code snippet to identify any external interactions such as database queries, \\\"\\n            f\\\"API calls, or file operations. For each detected interaction, return a JSON formatted list describing the interaction. \\\"\\n            f\\\"Each interaction should include the type, detailed description, and suggested mocking strategy if applicable. \\\"\\n            f\\\"Please classify the certainty of each interaction as 'high', 'medium', or 'low'. Based on the certainty, \\\"\\n            f\\\"provide appropriate mock ideas or indicate if mocking is not certain. Use the following response format:\\\\n\\\"\\n            f\\\"{json.dumps(json_example, indent=2)}\\\\n\\\"\\n            f\\\"If no external interactions are detected, please return an empty interactions array.\\\\n\\\"\\n            f\\\"Additionally, indicate the specific functions where these interactions occur.\\\\n\\\\n\\\"\\n            f\\\"```python\\\\n{function_implementation}\\\\n```\\\"\\n        )\\n\\n        # Call ChatGPT and get the response\\n        response = self.gpt_helper.call_chatgpt(prompt)\\n        interactions = self.parse_interaction_response(response)\\n        return interactions\\n\\n    def parse_interaction_response(self, response: str) -> List[Dict[str, Any]]:\\n        try:\\n            start_index = response.index(\\\"{\\\")\\n            end_index = response.rindex(\\\"}\\\") + 1\\n            json_str = response[start_index:end_index]\\n            interaction_data = json.loads(json_str)\\n            return interaction_data.get(\\\"interactions\\\", [])\\n        except (ValueError, json.JSONDecodeError) as e:\\n            logger.error(f\\\"Failed to decode interaction response from ChatGPT: {e}\\\")\\n            return []\\n\\n    def analyze_graph_for_interactions_and_context(\\n        self, graph: CallGraph, node_id: str, interactions: List[Dict[str, Any]], function_context: List[str]\\n    ):\\n        node_data = graph.graph.nodes[node_id]\\n        if (\\n            node_data[\\\"tag\\\"] == \\\"STDLIB\\\"\\n            or \\\"github_function_implementation\\\" not in node_data\\n            or node_data[\\\"github_function_implementation\\\"] == \\\"not_found\\\"\\n        ):\\n            return\\n\\n        node_interactions = self.analyze_external_interactions_with_chatgpt(node_data)\\n        interactions.extend(node_interactions)\\n\\n        function_context.append(\\n            f\\\"Function '{node_data['function']}' defined in '{node_data.get('github_file_path', 'unknown')}' at line {node_data.get('github_function_implementation', {}).get('start_line', 'unknown')} with this implementation {node_data.get('github_function_implementation', {}).get('content', 'Not available')} should consider the following details for mocking (if needed at all): {json.dumps(node_interactions)}\\\"\\n        )\\n\\n        for successor in graph.graph.successors(node_id):\\n            self.analyze_graph_for_interactions_and_context(graph, successor, interactions, function_context)\\n\\n    def generate_test_prompt(self, function_context, all_interactions, graph, entry_point_node_id):\\n        entry_point_data = graph.graph.nodes[entry_point_node_id]\\n\\n        # Load the pytest template from the resources directory\\n        template_path = os.path.join(os.path.dirname(__file__), \\\"resources\\\", \\\"pytest_template.py\\\")\\n        with open(template_path, \\\"r\\\") as file:\\n            pytest_template = file.read()\\n\\n        # Generate mock instructions only for high-certainty interactions\\n        mock_instructions = \\\"\\\\n\\\".join(\\n            interaction[\\\"mock_idea\\\"]\\n            for interaction in all_interactions\\n            if interaction.get(\\\"certainty\\\", \\\"low\\\") == \\\"high\\\" and \\\"mock_idea\\\" in interaction\\n        )\\n\\n        function_name = entry_point_data[\\\"function\\\"]\\n        file_path = entry_point_data.get(\\\"github_file_path\\\", \\\"unknown\\\")\\n        line_number = entry_point_data.get(\\\"github_function_implementation\\\", {}).get(\\\"start_line\\\", \\\"unknown\\\")\\n        function_implementation = entry_point_data.get(\\\"github_function_implementation\\\", {}).get(\\n            \\\"content\\\", \\\"Not available\\\"\\n        )\\n        full_function_content = entry_point_data.get(\\n            \\\"github_file_content\\\", \\\"Function content not available\\\"\\n        )  # Retrieve full function content\\n        arguments = json.dumps(entry_point_data.get(\\\"arguments\\\", {}), indent=2)\\n        expected_output = entry_point_data[\\\"return_value\\\"].get(\\\"json_serialized\\\", \\\"No output captured\\\")\\n        context_details = \\\"\\\\n\\\".join(function_context)\\n\\n        prompt = (\\n            f\\\"Write a complete pytest file for testing the WSGI app entry point '{function_name}' defined in '{file_path}' at line {line_number}. \\\"\\n            f\\\"Full function implementation from the source file:\\\\n{full_function_content}\\\\n\\\"\\n            f\\\"Function implementation snippet:\\\\n{function_implementation}\\\\n\\\"\\n            f\\\"Arguments: {arguments}\\\\n\\\"\\n            f\\\"Expected output: {expected_output}\\\\n\\\"\\n            \\\"Context and external interactions:\\\\n\\\"\\n            f\\\"{context_details}\\\\n\\\"\\n            \\\"External interactions to mock (follow the instructions below):\\\\n\\\"\\n            f\\\"{mock_instructions}\\\\n\\\"\\n            f\\\"\\\\n# --- Start of the Pytest Template ---\\\\n{pytest_template}\\\\n# --- End of the Pytest Template ---\\\\n\\\"\\n            \\\"Include necessary imports, setup any needed fixtures, and define test functions with assertions based on the expected output. \\\"\\n            \\\"Ensure the test file adheres to Python best practices and pytest conventions.\\\"\\n        )\\n\\n        return prompt\"}], \"DefinitionVisitor\": [{\"file_path\": \"serverside/src/utils/integrations/github_integration.py\", \"line_start\": 17, \"line_end\": 33, \"content\": \"class DefinitionVisitor(ast.NodeVisitor):\\n    \\\"\\\"\\\"Used to expose definitions met via self.definitions field\\\"\\\"\\\"\\n\\n    def __init__(self):\\n        self.definitions = []\\n\\n    def visit_ClassDef(self, node):\\n        self.definitions.append((\\\"class\\\", node))\\n        self.generic_visit(node)\\n\\n    def visit_FunctionDef(self, node):\\n        self.definitions.append((\\\"function\\\", node))\\n        self.generic_visit(node)\\n\\n    def visit_AsyncFunctionDef(self, node):\\n        self.definitions.append((\\\"function\\\", node))\\n        self.generic_visit(node)\"}], \"RepoHelper\": [{\"file_path\": \"serverside/src/utils/integrations/github_integration.py\", \"line_start\": 36, \"line_end\": 255, \"content\": \"class RepoHelper:\\n    def __init__(self, repo_url: str):\\n        self.repo_url = repo_url\\n        self.github_integration = self._get_integration()\\n        self.gh_repo = self._get_repo_by_url(repo_url)\\n        self.index = self._build_index()\\n\\n    def _get_integration(self) -> GithubIntegration:\\n        APP_ID = GITHUB_APP_ID\\n        PRIVATE_KEY = base64.b64decode(GITHUB_APP_PRIVATE_KEY_BASE64).decode(\\\"utf-8\\\")\\n        return GithubIntegration(APP_ID, PRIVATE_KEY)\\n\\n    def _get_repo_by_url(self, repo_url: str) -> Optional[Repository.Repository]:\\n        installations = self.github_integration.get_installations()\\n\\n        for installation in installations:\\n            for repo in installation.get_repos():\\n                if repo.html_url == repo_url:\\n                    return repo\\n        raise ValueError(f\\\"No matching installation was found for {repo_url}. Maybe the app is not installed yet.\\\")\\n\\n    def get_installation_by_url(self, repo_url: str) -> Optional[Repository.Repository]:\\n        installations = self.github_integration.get_installations()\\n\\n        for installation in installations:\\n            for repo in installation.get_repos():\\n                if repo.html_url == repo_url:\\n                    return installation\\n        raise ValueError(f\\\"No matching installation was found for {repo_url}. Maybe the app is not installed yet.\\\")\\n\\n    def enrich_callgraph_with_github_context(self, callgraph: CallGraph) -> None:\\n        for node_id in callgraph.graph.nodes:\\n            node = callgraph.graph.nodes[node_id]\\n            if \\\"function\\\" in node:\\n                enriched_node = self.enrich_node_with_github_data(node)\\n                if enriched_node:\\n                    callgraph.graph.nodes[node_id].update(enriched_node)\\n\\n    def _build_index(self) -> Dict[str, Dict[str, List[Dict[str, Any]]]]:\\n        index = {\\\"class\\\": {}, \\\"function\\\": {}}\\n        contents = self.gh_repo.get_contents(\\\"\\\")\\n        while contents:\\n            file_content = contents.pop(0)\\n            if file_content.type == \\\"dir\\\":\\n                contents.extend(self.gh_repo.get_contents(file_content.path))\\n            elif file_content.name.endswith(\\\".py\\\"):\\n                self._process_python_file(file_content, index)\\n        return index\\n\\n    def _process_python_file(self, file_content, index) -> None:\\n        try:\\n            file_data = file_content.decoded_content.decode(\\\"utf-8\\\")\\n            tree = ast.parse(file_data, filename=file_content.path)\\n            visitor = DefinitionVisitor()\\n            visitor.visit(tree)\\n            for symbol_type, node in visitor.definitions:\\n                symbol_name = node.name\\n                if symbol_name not in index[symbol_type]:\\n                    index[symbol_type][symbol_name] = []\\n                index[symbol_type][symbol_name].append(\\n                    {\\n                        \\\"file_path\\\": file_content.path,\\n                        \\\"line_start\\\": node.lineno,\\n                        \\\"line_end\\\": (node.end_lineno if hasattr(node, \\\"end_lineno\\\") else node.lineno),\\n                        \\\"content\\\": \\\"\\\\n\\\".join(\\n                            file_data.splitlines()[\\n                                node.lineno - 1 : (node.end_lineno if hasattr(node, \\\"end_lineno\\\") else node.lineno)\\n                            ]\\n                        ),\\n                    }\\n                )\\n        except Exception as e:\\n            logger.exception(f\\\"Error processing {file_content.path}: {e}\\\")\\n\\n    def lookup_index(self, symbol_name: str, symbol_type: str) -> Optional[Dict[str, Any]]:\\n        return self.index.get(symbol_type, {}).get(symbol_name)\\n\\n    def enrich_node_with_github_data(self, node):\\n        \\\"\\\"\\\"\\n        Enriches node attributes with:\\n            - file path from GitHub\\n            - function implementation from GitHub (start_line, end_line, content)\\n            - whole file content from GitHub\\n        \\\"\\\"\\\"\\n        symbol_name = node[\\\"function\\\"]\\n        symbol_type = \\\"function\\\"  # Assuming all nodes in the graph are functions for simplification\\n\\n        # Use the lookup_index method to find the function in the index\\n        defs = self.lookup_index(symbol_name, symbol_type)\\n\\n        if not defs:\\n            node[\\\"github_file_path\\\"] = \\\"not_found\\\"\\n            node[\\\"github_function_implementation\\\"] = \\\"not_found\\\"\\n            node[\\\"github_file_content\\\"] = \\\"not_found\\\"\\n            return\\n\\n        # For simplicity, take the first definition (if multiple are found, this may need refinement)\\n        def_info = defs[0]\\n\\n        # Load the whole file content\\n        try:\\n            file_content = self.gh_repo.get_contents(def_info[\\\"file_path\\\"]).decoded_content.decode(\\\"utf-8\\\")\\n        except Exception as e:\\n            logger.exception(f\\\"Error fetching file content for {def_info['file_path']}: {e}\\\")\\n            file_content = \\\"Error loading file content\\\"\\n\\n        # Update the node with GitHub data\\n        node.update(\\n            {\\n                \\\"github_file_path\\\": def_info[\\\"file_path\\\"],\\n                \\\"github_function_implementation\\\": {\\n                    \\\"start_line\\\": def_info[\\\"line_start\\\"],\\n                    \\\"end_line\\\": def_info[\\\"line_end\\\"],\\n                    \\\"content\\\": def_info[\\\"content\\\"],\\n                },\\n                \\\"github_file_content\\\": file_content,\\n            }\\n        )\\n\\n    def create_pull_request_with_new_function(\\n        self,\\n        node,\\n        exception_context: Dict[str, Any],\\n        new_implementation: str,\\n        change_reasoning: str,\\n        gpt_helper: OpenAIHelper,\\n    ):\\n        \\\"\\\"\\\"\\n        Update the implementation of a specific function based on node information,\\n        commit the changes to a new branch, and create a pull request with enhanced\\n        context including the exception chain.\\n\\n        Args:\\n            node: The graph node representing the function to be updated.\\n            new_implementation: The new source code for the function.\\n            gpt_helper: An instance of OpenAIHelper for any additional GPT-based processing.\\n            exception_chain: A list of dictionaries, each representing a node in the\\n                            exception chain. Each dictionary should contain at least\\n                            'function_name', 'file_line', and 'exception_info'.\\n        \\\"\\\"\\\"\\n        file_path = node[\\\"github_file_path\\\"]\\n        function_name = node[\\\"function\\\"]\\n        start_line = node[\\\"github_function_implementation\\\"][\\\"start_line\\\"]\\n        end_line = node[\\\"github_function_implementation\\\"][\\\"end_line\\\"]\\n        content = self.gh_repo.get_contents(file_path, ref=\\\"main\\\")\\n        source_code_lines = content.decoded_content.decode(\\\"utf-8\\\").splitlines()\\n\\n        # Replace old function implementation with new content within the source code lines\\n        new_code_lines = (\\n            source_code_lines[: start_line - 1] + new_implementation.splitlines() + source_code_lines[end_line:]\\n        )\\n        updated_source_code = \\\"\\\\n\\\".join(new_code_lines)\\n\\n        fix_styles_query = gpt_helper.generate_after_insert_style_query(updated_source_code, function_name)\\n        updated_source_code = gpt_helper.extract_first_code_block(gpt_helper.call_chatgpt(fix_styles_query))\\n\\n        # Create a new branch for this update\\n        new_branch_name = f\\\"update-{function_name}-{uuid.uuid4().hex}\\\"\\n        base_sha = self.gh_repo.get_branch(\\\"main\\\").commit.sha\\n        self.gh_repo.create_git_ref(ref=f\\\"refs/heads/{new_branch_name}\\\", sha=base_sha)\\n\\n        # Commit the updated file to the new branch\\n        commit_message = f\\\"Update implementation of {function_name}\\\"\\n        self.gh_repo.update_file(\\n            file_path,\\n            commit_message,\\n            updated_source_code,\\n            content.sha,\\n            branch=new_branch_name,\\n        )\\n\\n        # Create a pull request from the new branch to the main branch\\n        pr_title = f\\\"Improve {function_name} implementation\\\"\\n\\n        # Format the exception context for inclusion in the PR body.\\n        exception_context_md = \\\"### Detailed Exception Context\\\\n\\\\n\\\"\\n        for exception_node in exception_context[\\\"exception_nodes\\\"]:\\n            node_details = exception_node[\\\"node_details\\\"]\\n            exception_info = node_details.get(\\\"exception_info\\\", {})\\n            exception_context_md += (\\n                f\\\"- **Function**: {node_details['function_name']} at `{node_details['file_line']}`\\\\n\\\"\\n            )\\n            exception_context_md += f\\\"  - **Exception Type**: {exception_info.get('type')}\\\\n\\\"\\n            exception_context_md += f\\\"  - **Exception Value**: {exception_info.get('value')}\\\\n\\\"\\n            exception_context_md += \\\"\\\\n\\\"\\n\\n        change_reasoning_md = f\\\"### Change Reasoning\\\\n\\\\n{change_reasoning}\\\"\\n\\n        pr_body = f\\\"\\\"\\\"This pull request updates the implementation of `{node[\\\"function\\\"]}` to address the identified issues. Below is the context and reasoning behind these changes.\\\\n\\\\n{exception_context_md}\\\\n\\\\n{change_reasoning_md}\\\\n\\\\n```\\\"\\\"\\\"\\n\\n        pr = self.gh_repo.create_pull(title=pr_title, body=pr_body, head=new_branch_name, base=\\\"main\\\")\\n        logger.info(f\\\"Pull request created: {pr.html_url}\\\")\\n\\n    def create_pull_request_with_test(self, test_file_name: str, test_code: str, branch_name_suffix: str):\\n        \\\"\\\"\\\"\\n        Creates a new pull request with a new test file in the 'captureflow_tests/' directory.\\n\\n        Args:\\n            test_file_name (str): The name of the test file to create.\\n            test_code (str): The source code of the test.\\n            branch_name_suffix (str): A suffix for the branch name to ensure it is unique.\\n        \\\"\\\"\\\"\\n        # Define the path where the test file will be stored\\n        test_file_path = f\\\"captureflow_tests/{test_file_name}\\\"\\n\\n        # Create a new branch for this update\\n        new_branch_name = f\\\"add-test-{branch_name_suffix}-{uuid.uuid4().hex}\\\"\\n        base_sha = self.gh_repo.get_branch(\\\"main\\\").commit.sha\\n        self.gh_repo.create_git_ref(ref=f\\\"refs/heads/{new_branch_name}\\\", sha=base_sha)\\n\\n        # Create the test file on the new branch\\n        commit_message = f\\\"Add new test for {test_file_name}\\\"\\n        self.gh_repo.create_file(test_file_path, commit_message, test_code, branch=new_branch_name)\\n\\n        # Create a pull request from the new branch to the main branch\\n        pr_title = f\\\"Add new test for {test_file_name}\\\"\\n        pr_body = \\\"This pull request adds a new test file to improve the test coverage of the repository.\\\"\\n\\n        pr = self.gh_repo.create_pull(title=pr_title, body=pr_body, head=new_branch_name, base=\\\"main\\\")\\n        logger.info(f\\\"Pull request created: {pr.html_url}\\\")\"}], \"OpenAIHelper\": [{\"file_path\": \"serverside/src/utils/integrations/openai_integration.py\", \"line_start\": 14, \"line_end\": 169, \"content\": \"class OpenAIHelper:\\n    def __init__(self):\\n        self.client = self._create_openai_client()\\n\\n    def _create_openai_client(self) -> OpenAI:\\n        return OpenAI(api_key=OPENAI_KEY)\\n\\n    def generate_initial_scoring_query(self, node) -> str:\\n        cur_fun_name = node[\\\"function\\\"]\\n        cur_fun_impl = node[\\\"github_function_implementation\\\"]\\n        cur_file_impl = node[\\\"github_file_content\\\"]\\n\\n        query = f\\\"\\\"\\\"\\n            Imagine that you're the most competent programmer in San Francisco.\\n            You are tasked with making very safe update to a FUNCTION (not anything else), \\n            but you can improve readability/logic if you're 100% function will do exactly the same thing.\\n\\n            target_function: {cur_fun_name}\\n            function_code: {cur_fun_impl}\\n\\n            whole file code for context: ```{cur_file_impl}```\\n\\n            Please output JSON structuring your view on the question. It needs to have two fields: \\\"quality_score\\\" how much would you rate quality of this function from 1 to 10 and \\\"easy_to_optimize\\\" to label that takes values \\\"EASY_TO_OPTIMIZE\\\", \\\"MAYBE_OPTIMIZE\\\", \\\"HARD_OPTIMIZE\\\" representing if there is a safe refactoring available.\\n        \\\"\\\"\\\"\\n\\n        return query\\n\\n    def generate_improvement_query(self, call_graph, node) -> str:\\n        # Extract the required details from the log data\\n        cur_fun_name = node[\\\"function\\\"]\\n        cur_fun_path = node[\\\"github_file_path\\\"]\\n        cur_fun_impl = node[\\\"github_function_implementation\\\"]\\n        cur_fun_input = node[\\\"arguments\\\"]\\n        cur_fun_output = node[\\\"return_value\\\"]\\n        cur_file_impl = node[\\\"github_file_content\\\"]\\n\\n        # parent_nodes = list(call_graph.graph.predecessors(node_id))\\n        # children = list(call_graph.graph.successors(node_id))\\n\\n        query = f\\\"\\\"\\\"\\n            Imagine that you're the most competent programmer in San Francisco.\\n            You are tasked with making very safe update to a FUNCTION (not anything else), \\n            but you can improve readability/logic if you're 100% function will do exactly the same thing.\\n\\n            How function is actually implemented: \\n\\n            path: {cur_fun_path}, target_function: {cur_fun_name}\\n            function_code: {cur_fun_impl}\\n            example input: {cur_fun_input}\\n            example output: {cur_fun_output}\\n\\n            whole file code for context: ```{cur_file_impl}```\\n\\n            Please output only single thing, the proposed code of the same function. You can also leave comment in it, asking for for follow-ups.\\n        \\\"\\\"\\\"\\n\\n        return query\\n\\n    def generate_simulation_query(self, call_graph, node) -> str:\\n        # Extract the required details from the log data\\n        cur_fun_name = node[\\\"function\\\"]\\n        cur_fun_path = node[\\\"github_file_path\\\"]\\n        cur_fun_impl = (\\n            node[\\\"github_function_implementation\\\"][\\\"content\\\"]\\n            if \\\"github_function_implementation\\\" in node\\n            else \\\"Function implementation not found.\\\"\\n        )\\n        cur_fun_input = json.dumps(node.get(\\\"input_value\\\", {}), indent=2)\\n        cur_fun_output = json.dumps(node.get(\\\"return_value\\\", {}), indent=2)\\n        cur_file_impl = node[\\\"github_file_content\\\"]\\n\\n        query = f\\\"\\\"\\\"\\n            As a highly skilled software engineer, you're reviewing a Python function to ensure its correctness and readability. Here's the task:\\n\\n            - File path: {cur_fun_path}\\n            - Target function: {cur_fun_name}\\n\\n            The current implementation of the function is as follows:\\n            ```python\\n            {cur_fun_impl}\\n            ```\\n\\n            Given an example input:\\n            ```\\n            {cur_fun_input}\\n            ```\\n\\n            The function is expected to produce the following output:\\n            ```\\n            {cur_fun_output}\\n            ```\\n\\n            The context of the whole file where the function is located is provided for better understanding:\\n            ```python\\n            {cur_file_impl}\\n            ```\\n\\n            Simulate the environment: Run the improved function with the given example input and compare the output to the expected output.\\n            Finally, provide a confidence level (from 0 to 100%) on whether the improved function will consistently produce the correct output across various inputs, similar to the example provided.\\n            I only need one of three enums in your response \\\"MUST_WORK\\\", \\\"MAYBE_WORK\\\", \\\"DOESNT_WORK\\\". It will show how condident you are new function will function in exactly the same way.\\n            \\n            Also note that inputs and outputs are serialized but probably they're python objects you can deduct from this seralization code\\n            ```python\\n                def _serialize_variable(self, value: Any) -> Dict[str, Any]:\\n                    try:\\n                        json_value = json.dumps(value, default=str)\\n                    except TypeError:\\n                        json_value = str(value)\\n                    return {{\\n                        \\\"python_type\\\": str(type(value)),\\n                        \\\"json_serialized\\\": json_value\\n                    }}\\n            ```\\n        \\\"\\\"\\\"\\n\\n        return query.strip()\\n\\n    def generate_after_insert_style_query(self, new_file_code, function_name) -> str:\\n        query = f\\\"\\\"\\\"\\n            I have programatically changed source code of my file attempting to rewrite function called {function_name}.\\n            Important: I will give you source code of a file that contains this function, please make sure it aligns well with files (style, tabs, etc).\\n            Do nothing more and give me whole new script (even if nothing needs to be changed)!\\n            \\n            Here's script text: {new_file_code}\\n        \\\"\\\"\\\"\\n\\n        return query.strip()\\n\\n    def call_chatgpt(self, query: str) -> str:\\n        chat_completion = self.client.chat.completions.create(\\n            messages=[\\n                {\\n                    \\\"role\\\": \\\"user\\\",\\n                    \\\"content\\\": query,\\n                },\\n                {\\\"role\\\": \\\"system\\\", \\\"content\\\": \\\"You are a helpful assistant.\\\"},\\n            ],\\n            model=\\\"gpt-4\\\",\\n        )\\n\\n        assert len(chat_completion.choices) == 1\\n\\n        return chat_completion.choices[0].message.content\\n\\n    @staticmethod\\n    def extract_first_code_block(text: str) -> Optional[str]:\\n        pattern = r\\\"```(.*?)```\\\"\\n        match = re.search(pattern, text, re.DOTALL)\\n        code = match.group(1)\\n\\n        if match:\\n            code = code.lstrip(\\\"python\\\")\\n            code = code.lstrip(\\\"\\\\n\\\")\\n            return code\\n\\n        return None\"}]}, \"function\": {\"add\": [{\"file_path\": \"clientside/tests/test_fastapi_tracer.py\", \"line_start\": 20, \"line_end\": 21, \"content\": \"async def add(x: int, y: int):\\n    return {\\\"result\\\": x + y}\"}], \"test_trace_endpoint_fastapi\": [{\"file_path\": \"clientside/tests/test_fastapi_tracer.py\", \"line_start\": 25, \"line_end\": 48, \"content\": \"async def test_trace_endpoint_fastapi():\\n    with patch(\\\"src.captureflow.tracer.Tracer._send_trace_log\\\") as mock_log:\\n        with TestClient(app) as client:\\n            response = client.get(\\\"/add/2/3\\\")\\n            assert response.status_code == 200\\n            assert response.json() == {\\\"result\\\": 5}\\n\\n        mock_log.assert_called_once()\\n        log_data = mock_log.call_args[0][0]  # Get the context data passed to _send_trace_log\\n\\n        assert log_data[\\\"endpoint\\\"] == \\\"add\\\"\\n\\n        assert \\\"x\\\" in log_data[\\\"input\\\"][\\\"kwargs\\\"] and \\\"y\\\" in log_data[\\\"input\\\"][\\\"kwargs\\\"]\\n        assert log_data[\\\"input\\\"][\\\"kwargs\\\"][\\\"x\\\"][\\\"json_serialized\\\"] == json.dumps(2)  # Use json.dumps for consistency\\n        assert log_data[\\\"input\\\"][\\\"kwargs\\\"][\\\"y\\\"][\\\"json_serialized\\\"] == json.dumps(3)\\n\\n        assert len(log_data[\\\"execution_trace\\\"]) > 0\\n        assert log_data[\\\"execution_trace\\\"][0][\\\"event\\\"] == \\\"call\\\"\\n        assert log_data[\\\"output\\\"][\\\"result\\\"][\\\"json_serialized\\\"] == json.dumps({\\\"result\\\": 5})\\n\\n        # Additional checks for type information\\n        assert log_data[\\\"input\\\"][\\\"kwargs\\\"][\\\"x\\\"][\\\"python_type\\\"] == \\\"<class 'int'>\\\"\\n        assert log_data[\\\"input\\\"][\\\"kwargs\\\"][\\\"y\\\"][\\\"python_type\\\"] == \\\"<class 'int'>\\\"\\n        assert log_data[\\\"output\\\"][\\\"result\\\"][\\\"python_type\\\"] == \\\"<class 'dict'>\\\"\"}], \"divide\": [{\"file_path\": \"clientside/tests/test_fastapi_tracer.py\", \"line_start\": 53, \"line_end\": 54, \"content\": \"async def divide(x: int, y: int):\\n    return {\\\"result\\\": x / y}\"}], \"test_trace_endpoint_with_exception\": [{\"file_path\": \"clientside/tests/test_fastapi_tracer.py\", \"line_start\": 58, \"line_end\": 76, \"content\": \"async def test_trace_endpoint_with_exception():\\n    with patch(\\\"src.captureflow.tracer.Tracer._send_trace_log\\\") as mock_log:\\n        with TestClient(app, raise_server_exceptions=False) as client:\\n            response = client.get(\\\"/divide/10/0\\\")\\n            assert response.status_code == 500\\n\\n        mock_log.assert_called_once()\\n        log_data = mock_log.call_args[0][0]\\n\\n        assert log_data[\\\"endpoint\\\"] == \\\"divide\\\"\\n        assert \\\"x\\\" in log_data[\\\"input\\\"][\\\"kwargs\\\"] and \\\"y\\\" in log_data[\\\"input\\\"][\\\"kwargs\\\"]\\n        assert log_data[\\\"input\\\"][\\\"kwargs\\\"][\\\"x\\\"][\\\"json_serialized\\\"] == json.dumps(10)\\n        assert log_data[\\\"input\\\"][\\\"kwargs\\\"][\\\"y\\\"][\\\"json_serialized\\\"] == json.dumps(0)\\n\\n        exception_events = [e for e in log_data[\\\"execution_trace\\\"] if e[\\\"event\\\"] == \\\"exception\\\"]\\n        assert len(exception_events) > 0, \\\"Exception event not found in the execution trace\\\"\\n        exception_event = exception_events[0]\\n        assert \\\"ZeroDivisionError\\\" in exception_event[\\\"exception_info\\\"][\\\"type\\\"], \\\"Expected ZeroDivisionError\\\"\\n        assert \\\"division by zero\\\" in exception_event[\\\"exception_info\\\"][\\\"value\\\"], \\\"Expected 'division by zero' message\\\"\"}], \"parse_execution_trace\": [{\"file_path\": \"serverside/src/server.py\", \"line_start\": 70, \"line_end\": 81, \"content\": \"    def parse_execution_trace(cls, v):\\n        items = []\\n        mapping = {\\n            \\\"call\\\": CallExecutionTraceItem,\\n            \\\"line\\\": LineExecutionTraceItem,\\n            \\\"exception\\\": ExceptionExecutionTraceItem,\\n            \\\"return\\\": ReturnExecutionTraceItem,\\n        }\\n        for item in v:\\n            item_type = mapping.get(item.get(\\\"event\\\"), BaseExecutionTraceItem)\\n            items.append(parse_obj_as(item_type, item))\\n        return items\"}], \"store_trace_log\": [{\"file_path\": \"serverside/src/server.py\", \"line_start\": 86, \"line_end\": 91, \"content\": \"async def store_trace_log(trace_data: TraceData, repo_url: str = Query(..., alias=\\\"repository-url\\\")):\\n    trace_data_json = trace_data.json()\\n    trace_log_key = f\\\"{repo_url}:{trace_data.invocation_id}\\\"\\n\\n    redis.set(trace_log_key, trace_data_json)\\n    return {\\\"message\\\": \\\"Trace log saved successfully\\\"}\"}], \"generate_bugfix_mr\": [{\"file_path\": \"serverside/src/server.py\", \"line_start\": 96, \"line_end\": 99, \"content\": \"async def generate_bugfix_mr(repo_url: str = Query(..., alias=\\\"repository-url\\\")):\\n    orchestrator = ExceptionPatcher(redis_client=redis, repo_url=repo_url)\\n    orchestrator.run()\\n    return {\\\"message\\\": \\\"MR generation process started successfully\\\"}\"}], \"generate_test_coverage\": [{\"file_path\": \"serverside/src/server.py\", \"line_start\": 103, \"line_end\": 110, \"content\": \"async def generate_test_coverage(repo_url: str = Query(..., alias=\\\"repository-url\\\")):\\n    \\\"\\\"\\\"\\n    Endpoint to trigger test coverage creation using the TestCoverageCreator.\\n    The process will look at non-standard library functions in the trace and attempt to generate tests.\\n    \\\"\\\"\\\"\\n    test_creator = TestCoverageCreator(redis_client=redis, repo_url=repo_url)\\n    test_creator.run()\\n    return {\\\"message\\\": \\\"Test coverage creation process initiated successfully\\\"}\"}], \"mock_openai_helper\": [{\"file_path\": \"serverside/tests/conftest.py\", \"line_start\": 12, \"line_end\": 16, \"content\": \"def mock_openai_helper():\\n    with patch.object(OpenAIHelper, \\\"_create_openai_client\\\", return_value=MagicMock()):\\n        mock_helper = OpenAIHelper()\\n        mock_helper.call_chatgpt = MagicMock(return_value=\\\"Mocked GPT response\\\")\\n        yield mock_helper\"}, {\"file_path\": \"serverside/tests/utils/test_creator.py\", \"line_start\": 37, \"line_end\": 51, \"content\": \"def mock_openai_helper():\\n    with patch(\\\"src.utils.integrations.openai_integration.OpenAIHelper\\\") as MockOpenAIHelper:\\n        mock_helper = MockOpenAIHelper()\\n        mock_helper.call_chatgpt.side_effect = [\\n            json.dumps(\\n                {\\n                    \\\"interactions\\\": [\\n                        {\\\"type\\\": \\\"DB_INTERACTION\\\", \\\"details\\\": \\\"Mock DB query\\\", \\\"mock_idea\\\": \\\"mock_db_query()\\\"}\\n                    ]\\n                }\\n            ),  # Second call for INTERNAL function\\n            \\\"```python\\\\ndef test_calculate_average(): assert True```\\\",  # Second call for generating full pytest code\\n        ]\\n        mock_helper.extract_first_code_block.return_value = \\\"def test_calculate_average(): assert True\\\"\\n        yield mock_helper\"}, {\"file_path\": \"serverside/tests/utils/test_exception_patcher.py\", \"line_start\": 45, \"line_end\": 62, \"content\": \"def mock_openai_helper():\\n    with patch(\\\"src.utils.integrations.openai_integration.OpenAIHelper\\\") as MockOpenAIHelper:\\n        mock_helper = MockOpenAIHelper()\\n        # Mocking expected ChatGPT response structure\\n        dummy_function_code = \\\"def dummy_function(): pass\\\"\\n        mock_response_json_str = json.dumps(\\n            {\\n                \\\"confidence\\\": 5,\\n                \\\"function_name\\\": \\\"calculate_avg\\\",\\n                \\\"change_reasoning\\\": \\\"Just a mock response.\\\",\\n            }\\n        )\\n        mock_response_code_str = f\\\"```python\\\\n{dummy_function_code}```\\\"\\n        mock_response = f\\\"{mock_response_json_str}\\\\n{mock_response_code_str}\\\"\\n        mock_helper.call_chatgpt.return_value = mock_response\\n        mock_helper.extract_first_code_block.return_value = dummy_function_code\\n\\n        yield mock_helper\"}], \"mock_repo_helper\": [{\"file_path\": \"serverside/tests/conftest.py\", \"line_start\": 20, \"line_end\": 25, \"content\": \"def mock_repo_helper():\\n    with patch.object(RepoHelper, \\\"_get_integration\\\", return_value=MagicMock()):\\n        mock_helper = RepoHelper(\\\"mock://repo_url\\\")\\n        mock_helper.enrich_callgraph_with_github_context = MagicMock(return_value=None)\\n        mock_helper.create_pull_request_with_new_function = MagicMock(return_value=None)\\n        yield mock_helper\"}, {\"file_path\": \"serverside/tests/utils/test_creator.py\", \"line_start\": 70, \"line_end\": 83, \"content\": \"def mock_repo_helper(github_data_mapping):\\n    def mock_enrich_callgraph_with_github_context(callgraph: CallGraph) -> None:\\n        for node_id in callgraph.graph.nodes:\\n            node = callgraph.graph.nodes[node_id]\\n            if \\\"function\\\" in node:\\n                enriched_node = github_data_mapping.get(node[\\\"function\\\"])\\n                if enriched_node:\\n                    callgraph.graph.nodes[node_id].update(enriched_node)\\n\\n    mock_instance = Mock()\\n    mock_instance._get_repo_by_url.return_value = Mock(html_url=\\\"http://sample.repo.url\\\")\\n    mock_instance.enrich_callgraph_with_github_context.side_effect = mock_enrich_callgraph_with_github_context\\n\\n    return mock_instance\"}, {\"file_path\": \"serverside/tests/utils/test_exception_patcher.py\", \"line_start\": 90, \"line_end\": 103, \"content\": \"def mock_repo_helper(github_data_mapping):\\n    def mock_enrich_callgraph_with_github_context(callgraph: CallGraph) -> None:\\n        for node_id in callgraph.graph.nodes:\\n            node = callgraph.graph.nodes[node_id]\\n            if \\\"function\\\" in node:\\n                enriched_node = github_data_mapping.get(node[\\\"function\\\"])\\n                if enriched_node:\\n                    callgraph.graph.nodes[node_id].update(enriched_node)\\n\\n    mock_instance = Mock()\\n    mock_instance._get_repo_by_url.return_value = Mock(html_url=\\\"http://sample.repo.url\\\")\\n    mock_instance.enrich_callgraph_with_github_context.side_effect = mock_enrich_callgraph_with_github_context\\n\\n    return mock_instance\"}], \"client\": [{\"file_path\": \"serverside/tests/test_server.py\", \"line_start\": 13, \"line_end\": 15, \"content\": \"def client():\\n    with TestClient(app) as client:\\n        yield client\"}, {\"file_path\": \"serverside/src/utils/resources/pytest_template.py\", \"line_start\": 10, \"line_end\": 13, \"content\": \"def client():\\n    \\\"\\\"\\\"Provides a test client for the FastAPI application.\\\"\\\"\\\"\\n    with TestClient(app) as client:\\n        yield client\"}], \"mock_redis\": [{\"file_path\": \"serverside/tests/test_server.py\", \"line_start\": 19, \"line_end\": 22, \"content\": \"def mock_redis(mocker):\\n    mock_redis = MagicMock()\\n    mocker.patch(\\\"src.server.redis\\\", new=mock_redis)\\n    return mock_redis\"}], \"sample_trace\": [{\"file_path\": \"serverside/tests/test_server.py\", \"line_start\": 26, \"line_end\": 29, \"content\": \"def sample_trace():\\n    trace_path = Path(__file__).parent / \\\"assets\\\" / \\\"sample_trace.json\\\"\\n    with open(trace_path) as f:\\n        return json.load(f)\"}, {\"file_path\": \"serverside/tests/utils/test_call_graph.py\", \"line_start\": 10, \"line_end\": 13, \"content\": \"def sample_trace():\\n    trace_path = Path(__file__).parent.parent / \\\"assets\\\" / \\\"sample_trace.json\\\"\\n    with open(trace_path) as f:\\n        return json.load(f)\"}], \"sample_trace_with_exception\": [{\"file_path\": \"serverside/tests/test_server.py\", \"line_start\": 33, \"line_end\": 36, \"content\": \"def sample_trace_with_exception():\\n    trace_path = Path(__file__).parent / \\\"assets\\\" / \\\"sample_trace_with_exception.json\\\"\\n    with open(trace_path) as f:\\n        return json.load(f)\"}], \"normalize_trace_data\": [{\"file_path\": \"serverside/tests/test_server.py\", \"line_start\": 39, \"line_end\": 47, \"content\": \"def normalize_trace_data(data: Dict[str, Any]) -> Dict[str, Any]:\\n    \\\"\\\"\\\"\\n    Normalizes trace data by ensuring optional fields are present and correctly formatted.\\n    \\\"\\\"\\\"\\n\\n    if \\\"output\\\" not in data:\\n        data[\\\"output\\\"] = None\\n\\n    return data\"}], \"test_store_trace_log\": [{\"file_path\": \"serverside/tests/test_server.py\", \"line_start\": 50, \"line_end\": 71, \"content\": \"def test_store_trace_log(client, mock_redis, sample_trace):\\n    repo_url = \\\"https://github.com/NickKuts/capture_flow\\\"\\n    response = client.post(\\\"/api/v1/traces\\\", params={\\\"repository-url\\\": repo_url}, json=sample_trace)\\n\\n    assert response.status_code == 200\\n    assert response.json() == {\\\"message\\\": \\\"Trace log saved successfully\\\"}\\n\\n    # Verify Redis 'set' was called\\n    assert mock_redis.set.called, \\\"Redis 'set' method was not called\\\"\\n    called_args, _ = mock_redis.set.call_args\\n    key_passed_to_redis, json_data_passed_to_redis = called_args\\n\\n    expected_key = f\\\"{repo_url}:{sample_trace['invocation_id']}\\\"\\n    assert key_passed_to_redis == expected_key, \\\"Key passed to Redis does not match expected format\\\"\\n\\n    # Deserialize & normalize\\n    actual_data = json.loads(json_data_passed_to_redis)\\n    actual_data = normalize_trace_data(actual_data)\\n    expected_data = normalize_trace_data(sample_trace)\\n\\n    # Compare normalized data\\n    assert actual_data == expected_data, \\\"Normalized data passed to Redis does not match expected data\\\"\"}], \"test_store_trace_log_with_exception\": [{\"file_path\": \"serverside/tests/test_server.py\", \"line_start\": 74, \"line_end\": 95, \"content\": \"def test_store_trace_log_with_exception(client, mock_redis, sample_trace_with_exception):\\n    repo_url = \\\"https://github.com/NickKuts/capture_flow\\\"\\n    response = client.post(\\\"/api/v1/traces\\\", params={\\\"repository-url\\\": repo_url}, json=sample_trace_with_exception)\\n\\n    assert response.status_code == 200\\n    assert response.json() == {\\\"message\\\": \\\"Trace log saved successfully\\\"}\\n\\n    # Verify Redis 'set' was called\\n    assert mock_redis.set.called, \\\"Redis 'set' method was not called\\\"\\n    called_args, _ = mock_redis.set.call_args\\n    key_passed_to_redis, json_data_passed_to_redis = called_args\\n\\n    expected_key = f\\\"{repo_url}:{sample_trace_with_exception['invocation_id']}\\\"\\n    assert key_passed_to_redis == expected_key, \\\"Key passed to Redis does not match expected format\\\"\\n\\n    # Deserialize & normalize\\n    actual_data = json.loads(json_data_passed_to_redis)\\n    actual_data = normalize_trace_data(actual_data)\\n    expected_data = normalize_trace_data(sample_trace_with_exception)\\n\\n    # Compare normalized data\\n    assert actual_data == expected_data, \\\"Normalized data passed to Redis does not match expected data\\\"\"}], \"startup_event\": [{\"file_path\": \"clientside/examples/fastapi/server.py\", \"line_start\": 22, \"line_end\": 24, \"content\": \"async def startup_event():\\n    \\\"\\\"\\\"Initialize the database on startup.\\\"\\\"\\\"\\n    utilz.init_db()\"}], \"score_transaction\": [{\"file_path\": \"clientside/examples/fastapi/server.py\", \"line_start\": 29, \"line_end\": 48, \"content\": \"async def score_transaction(transaction: Transaction):\\n    \\\"\\\"\\\"\\n    Scores a given transaction for fraud potential based on amount similarity to the last 5 transactions for the same company_id.\\n\\n    ## cURL examples:\\n    ```\\n    curl -X 'POST' 'http://127.0.0.1:1337/score_transaction/' -H 'accept: application/json' -H 'Content-Type: application/json' -d '{\\\"user_id\\\": \\\"user123\\\", \\\"company_id\\\": \\\"company456\\\", \\\"amount\\\": 100.0}'\\n    ```\\n    \\\"\\\"\\\"\\n    score = utilz.calculate_score(transaction.user_id, transaction.company_id, transaction.amount)\\n    try:\\n        utilz.add_transaction(transaction.user_id, transaction.company_id, transaction.amount, score)\\n    except Exception as e:\\n        raise HTTPException(status_code=500, detail=str(e))\\n    return {\\n        \\\"user_id\\\": transaction.user_id,\\n        \\\"company_id\\\": transaction.company_id,\\n        \\\"amount\\\": transaction.amount,\\n        \\\"score\\\": score,\\n    }\"}], \"init_db\": [{\"file_path\": \"clientside/examples/fastapi/utilz.py\", \"line_start\": 6, \"line_end\": 25, \"content\": \"def init_db():\\n    with sqlite3.connect(DATABASE_URL) as conn:\\n        cursor = conn.cursor()\\n        cursor.execute(\\n            \\\"\\\"\\\"\\n            CREATE TABLE IF NOT EXISTS transactions (\\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\\n                user_id TEXT NOT NULL,\\n                company_id TEXT NOT NULL,\\n                amount REAL NOT NULL,\\n                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\\n                score REAL DEFAULT 0.0\\n            );\\n        \\\"\\\"\\\"\\n        )\\n        # Pre-populate the database with a transaction\\n        cursor.execute(\\n            \\\"INSERT INTO transactions (user_id, company_id, amount, score) VALUES ('user123', 'company456', 100.0, 0.5)\\\"\\n        )\\n        conn.commit()\"}], \"calculate_score\": [{\"file_path\": \"clientside/examples/fastapi/utilz.py\", \"line_start\": 28, \"line_end\": 46, \"content\": \"def calculate_score(user_id: str, company_id: str, amount: float) -> float:\\n    # Intentional error trigger for a specific company_id\\n    if company_id == \\\"errorTrigger\\\":\\n        raise ValueError(\\\"Intentional Error Triggered\\\")\\n\\n    with sqlite3.connect(DATABASE_URL) as conn:\\n        cursor = conn.cursor()\\n        cursor.execute(\\n            \\\"\\\"\\\"\\n            SELECT amount FROM transactions\\n            WHERE company_id = ?\\n            ORDER BY timestamp DESC\\n            LIMIT 5\\n        \\\"\\\"\\\",\\n            (company_id,),\\n        )\\n        past_amounts = cursor.fetchall()\\n        score = amount / sum([amt[0] for amt in past_amounts])\\n        return score\"}], \"add_transaction\": [{\"file_path\": \"clientside/examples/fastapi/utilz.py\", \"line_start\": 49, \"line_end\": 59, \"content\": \"def add_transaction(user_id: str, company_id: str, amount: float, score: float):\\n    with sqlite3.connect(DATABASE_URL) as conn:\\n        cursor = conn.cursor()\\n        cursor.execute(\\n            \\\"\\\"\\\"\\n            INSERT INTO transactions (user_id, company_id, amount, score)\\n            VALUES (?, ?, ?, ?)\\n        \\\"\\\"\\\",\\n            (user_id, company_id, amount, score),\\n        )\\n        conn.commit()\"}], \"__init__\": [{\"file_path\": \"clientside/src/captureflow/tracer.py\", \"line_start\": 26, \"line_end\": 29, \"content\": \"    def __init__(self, repo_url: str, server_base_url: str = \\\"http://127.0.0.1:8000\\\"):\\n        \\\"\\\"\\\"Initialize the tracer with the repository URL and optionally the remote logging URL.\\\"\\\"\\\"\\n        self.repo_url = repo_url\\n        self.trace_endpoint_url = f\\\"{server_base_url.rstrip('/')}/api/v1/traces\\\"\"}, {\"file_path\": \"serverside/src/utils/call_graph.py\", \"line_start\": 11, \"line_end\": 13, \"content\": \"    def __init__(self, log_data: str):\\n        self.graph = nx.DiGraph()\\n        self._build_graph(log_data)\"}, {\"file_path\": \"serverside/src/utils/docker_executor.py\", \"line_start\": 28, \"line_end\": 30, \"content\": \"    def __init__(self, test_coverage: dict[Path, TestCoverageItem], pytest_raw_output: str):\\n        self.test_coverage = test_coverage\\n        self.pytest_raw_output = pytest_raw_output\"}, {\"file_path\": \"serverside/src/utils/docker_executor.py\", \"line_start\": 36, \"line_end\": 41, \"content\": \"    def __init__(self, repo_url):\\n        \\\"\\\"\\\"\\n        User repo will have .captureflow['run-tests']\\n        \\\"\\\"\\\"\\n        self.repo_url = repo_url\\n        self.repo_helper = RepoHelper(repo_url=self.repo_url)\"}, {\"file_path\": \"serverside/src/utils/exception_patcher.py\", \"line_start\": 16, \"line_end\": 20, \"content\": \"    def __init__(self, redis_client: Redis, repo_url: str):\\n        self.redis_client = redis_client\\n        self.repo_url = repo_url\\n        self.repo_helper = RepoHelper(repo_url)\\n        self.gpt_helper = OpenAIHelper()\"}, {\"file_path\": \"serverside/src/utils/test_creator.py\", \"line_start\": 17, \"line_end\": 21, \"content\": \"    def __init__(self, redis_client: Redis, repo_url: str):\\n        self.redis_client = redis_client\\n        self.repo_url = repo_url\\n        self.gpt_helper = OpenAIHelper()\\n        self.repo_helper = RepoHelper(repo_url)\"}, {\"file_path\": \"serverside/src/utils/integrations/github_integration.py\", \"line_start\": 20, \"line_end\": 21, \"content\": \"    def __init__(self):\\n        self.definitions = []\"}, {\"file_path\": \"serverside/src/utils/integrations/github_integration.py\", \"line_start\": 37, \"line_end\": 41, \"content\": \"    def __init__(self, repo_url: str):\\n        self.repo_url = repo_url\\n        self.github_integration = self._get_integration()\\n        self.gh_repo = self._get_repo_by_url(repo_url)\\n        self.index = self._build_index()\"}, {\"file_path\": \"serverside/src/utils/integrations/openai_integration.py\", \"line_start\": 15, \"line_end\": 16, \"content\": \"    def __init__(self):\\n        self.client = self._create_openai_client()\"}], \"trace_endpoint\": [{\"file_path\": \"clientside/src/captureflow/tracer.py\", \"line_start\": 31, \"line_end\": 63, \"content\": \"    def trace_endpoint(self, func: Callable) -> Callable:\\n        \\\"\\\"\\\"Decorator to trace endpoint function calls.\\\"\\\"\\\"\\n\\n        # TODO: Give option to specify log \\\"verbosity\\\"\\n        #       Max verbosity                           => need \\\"heavy\\\" sys.settrace()\\n        #           Subgoal: investigate sampling of requests (e.g. log every N-th request) to make it less \\\"heavy\\\"\\n        #       Min verbosity (e.g. only exceptions)    => we could patch Flask/FastAPI methods and that would be better performance wise\\n        @wraps(func)\\n        async def wrapper(*args, **kwargs) -> Any:\\n            try:\\n                invocation_id = str(uuid.uuid4())\\n                context = {\\n                    \\\"invocation_id\\\": invocation_id,\\n                    \\\"timestamp\\\": datetime.now().isoformat(),\\n                    \\\"endpoint\\\": func.__qualname__,\\n                    \\\"input\\\": {\\n                        \\\"args\\\": [self._serialize_variable(arg) for arg in args],\\n                        \\\"kwargs\\\": {k: self._serialize_variable(v) for k, v in kwargs.items()},\\n                    },\\n                    \\\"execution_trace\\\": [],\\n                    \\\"log_filename\\\": f\\\"{TEMP_FOLDER}{func.__name__}_trace_{invocation_id}.json\\\",\\n                }\\n\\n                sys.settrace(self._setup_trace(context))\\n                result = await func(*args, **kwargs) if asyncio.iscoroutinefunction(func) else func(*args, **kwargs)\\n                context[\\\"output\\\"] = {\\\"result\\\": self._serialize_variable(result)}\\n            finally:\\n                sys.settrace(None)\\n                self._send_trace_log(context)\\n\\n            return result\\n\\n        return wrapper\"}], \"wrapper\": [{\"file_path\": \"clientside/src/captureflow/tracer.py\", \"line_start\": 39, \"line_end\": 61, \"content\": \"        async def wrapper(*args, **kwargs) -> Any:\\n            try:\\n                invocation_id = str(uuid.uuid4())\\n                context = {\\n                    \\\"invocation_id\\\": invocation_id,\\n                    \\\"timestamp\\\": datetime.now().isoformat(),\\n                    \\\"endpoint\\\": func.__qualname__,\\n                    \\\"input\\\": {\\n                        \\\"args\\\": [self._serialize_variable(arg) for arg in args],\\n                        \\\"kwargs\\\": {k: self._serialize_variable(v) for k, v in kwargs.items()},\\n                    },\\n                    \\\"execution_trace\\\": [],\\n                    \\\"log_filename\\\": f\\\"{TEMP_FOLDER}{func.__name__}_trace_{invocation_id}.json\\\",\\n                }\\n\\n                sys.settrace(self._setup_trace(context))\\n                result = await func(*args, **kwargs) if asyncio.iscoroutinefunction(func) else func(*args, **kwargs)\\n                context[\\\"output\\\"] = {\\\"result\\\": self._serialize_variable(result)}\\n            finally:\\n                sys.settrace(None)\\n                self._send_trace_log(context)\\n\\n            return result\"}], \"_send_trace_log\": [{\"file_path\": \"clientside/src/captureflow/tracer.py\", \"line_start\": 65, \"line_end\": 81, \"content\": \"    def _send_trace_log(self, context: Dict[str, Any]) -> None:\\n        if os.environ.get(\\\"CAPTUREFLOW_DEV_SERVER\\\") == \\\"true\\\":\\n            log_filename = f\\\"trace_{context['invocation_id']}.json\\\"\\n            with open(log_filename, \\\"w\\\") as f:\\n                json.dump(context, f, indent=4)\\n\\n        try:\\n            response = requests.post(\\n                self.trace_endpoint_url,\\n                params={\\\"repository-url\\\": self.repo_url},  # TODO: move param to HTTP body\\n                json=context,\\n                headers={\\\"Content-Type\\\": \\\"application/json\\\"},\\n            )\\n            if response.status_code != 200:\\n                logger.info(f\\\"CaptureFlow server responded: {response.status_code}\\\")\\n        except Exception as e:\\n            logger.info(f\\\"Exception during logging: {e}\\\")\"}], \"_serialize_variable\": [{\"file_path\": \"clientside/src/captureflow/tracer.py\", \"line_start\": 83, \"line_end\": 93, \"content\": \"    def _serialize_variable(self, value: Any) -> Dict[str, Any]:\\n        try:\\n            json_value = json.dumps(value)\\n        except Exception as e:\\n            try:\\n                json_value = str(value)  # If the value cannot be serialized to JSON, use str() / repr()\\n            except Exception as e:\\n                json_value = \\\"<unrepresentable object>\\\"  # Very rare case, but can happen with e.g. MagicMocks\\n                logger.info(f\\\"Failed to convert variable to string. Type: {type(value)}, Error: {e}\\\")\\n\\n        return {\\\"python_type\\\": str(type(value)), \\\"json_serialized\\\": json_value}\"}], \"_get_file_tag\": [{\"file_path\": \"clientside/src/captureflow/tracer.py\", \"line_start\": 95, \"line_end\": 101, \"content\": \"    def _get_file_tag(self, file_path: str) -> str:\\n        \\\"\\\"\\\"Determine the file tag based on the file path.\\\"\\\"\\\"\\n        if STDLIB_PATH in file_path:\\n            return \\\"STDLIB\\\"\\n        elif LIBRARY_PATH in file_path:\\n            return \\\"LIBRARY\\\"\\n        return \\\"INTERNAL\\\"\"}], \"_setup_trace\": [{\"file_path\": \"clientside/src/captureflow/tracer.py\", \"line_start\": 103, \"line_end\": 106, \"content\": \"    def _setup_trace(self, context: Dict[str, Any]) -> Callable:\\n        \\\"\\\"\\\"Setup the trace function.\\\"\\\"\\\"\\n        context[\\\"call_stack\\\"] = []\\n        return lambda frame, event, arg: self._trace_function_calls(frame, event, arg, context)\"}], \"_capture_arguments\": [{\"file_path\": \"clientside/src/captureflow/tracer.py\", \"line_start\": 108, \"line_end\": 124, \"content\": \"    def _capture_arguments(self, frame) -> Dict[str, Any]:\\n        \\\"\\\"\\\"\\n        Capture arguments passed to the function and serialize them.\\n        This simplified version does not distinguish between args and kwargs based on the function's signature.\\n        \\\"\\\"\\\"\\n        args, _, _, values = inspect.getargvalues(frame)\\n\\n        serialized_args = []\\n        serialized_kwargs = {}\\n        for arg in args:\\n            serialized_value = self._serialize_variable(values[arg])\\n            if arg == \\\"args\\\" or arg.startswith(\\\"arg\\\"):\\n                serialized_args.append(serialized_value)\\n            else:\\n                serialized_kwargs[arg] = serialized_value\\n\\n        return {\\\"args\\\": serialized_args, \\\"kwargs\\\": serialized_kwargs}\"}], \"_trace_function_calls\": [{\"file_path\": \"clientside/src/captureflow/tracer.py\", \"line_start\": 126, \"line_end\": 166, \"content\": \"    def _trace_function_calls(self, frame, event, arg, context: Dict[str, Any]) -> Callable:\\n        \\\"\\\"\\\"Trace function calls and capture relevant data.\\\"\\\"\\\"\\n        code = frame.f_code\\n        func_name, file_name, line_no = code.co_name, code.co_filename, frame.f_lineno\\n\\n        tag = self._get_file_tag(file_name)\\n        caller_id = context[\\\"call_stack\\\"][-1][\\\"id\\\"] if context[\\\"call_stack\\\"] else None\\n\\n        call_id = str(uuid.uuid4())\\n        trace_event = {\\n            \\\"id\\\": call_id,\\n            \\\"timestamp\\\": datetime.now().isoformat(),\\n            \\\"event\\\": event,\\n            \\\"function\\\": func_name,\\n            \\\"caller_id\\\": caller_id,\\n            \\\"file\\\": file_name,\\n            \\\"line\\\": line_no,\\n            \\\"source_line\\\": linecache.getline(file_name, line_no).strip(),\\n            \\\"tag\\\": tag,\\n        }\\n\\n        if event == \\\"call\\\":\\n            trace_event[\\\"arguments\\\"] = self._capture_arguments(frame)\\n            context[\\\"call_stack\\\"].append(trace_event)\\n        elif event == \\\"return\\\":\\n            trace_event[\\\"return_value\\\"] = self._serialize_variable(arg)\\n            # Also update \\\"call\\\" frame, because it's quick\\n            if context[\\\"call_stack\\\"]:\\n                context[\\\"call_stack\\\"][-1][\\\"return_value\\\"] = self._serialize_variable(arg)\\n                context[\\\"call_stack\\\"].pop()\\n        elif event == \\\"exception\\\":\\n            exc_type, exc_value, exc_traceback = arg\\n            trace_event[\\\"exception_info\\\"] = {\\n                \\\"type\\\": str(exc_type.__name__),\\n                \\\"value\\\": str(exc_value),\\n                \\\"traceback\\\": traceback.format_tb(exc_traceback),\\n            }\\n\\n        context[\\\"execution_trace\\\"].append(trace_event)\\n\\n        return lambda frame, event, arg: self._trace_function_calls(frame, event, arg, context)\"}], \"_build_graph\": [{\"file_path\": \"serverside/src/utils/call_graph.py\", \"line_start\": 15, \"line_end\": 52, \"content\": \"    def _build_graph(self, log_data: str) -> None:\\n        data = json.loads(log_data) if isinstance(log_data, str) else log_data\\n        # Track nodes that threw exceptions\\n        exception_nodes = {}\\n\\n        for event in data[\\\"execution_trace\\\"]:\\n            if event[\\\"event\\\"] in [\\\"call\\\", \\\"exception\\\"]:\\n                if event[\\\"event\\\"] == \\\"call\\\":\\n                    node_attrs = {\\n                        \\\"function\\\": event[\\\"function\\\"],\\n                        \\\"file_line\\\": f\\\"{event['file']}:{event['line']}\\\",\\n                        \\\"tag\\\": event.get(\\\"tag\\\", \\\"INTERNAL\\\"),\\n                        \\\"arguments\\\": event.get(\\\"arguments\\\", {}),\\n                        \\\"return_value\\\": event.get(\\\"return_value\\\", {}),\\n                        \\\"exception\\\": False,  # Initialize nodes with no exception\\n                    }\\n                elif event[\\\"event\\\"] == \\\"exception\\\":\\n                    # Update the caller node with exception info\\n                    caller_node = self.graph.nodes[event[\\\"caller_id\\\"]]\\n                    caller_node[\\\"did_raise\\\"] = True\\n                    caller_node[\\\"unhandled_exception\\\"] = {\\n                        \\\"type\\\": event[\\\"exception_info\\\"][\\\"type\\\"],\\n                        \\\"value\\\": event[\\\"exception_info\\\"][\\\"value\\\"],\\n                        \\\"traceback\\\": event[\\\"exception_info\\\"][\\\"traceback\\\"],\\n                    }\\n\\n                    continue\\n\\n                self.graph.add_node(event[\\\"id\\\"], **node_attrs)\\n\\n                # Add an edge from the caller to the current function call\\n                caller_id = event.get(\\\"caller_id\\\")\\n                if caller_id and caller_id in self.graph:\\n                    self.graph.add_edge(caller_id, event[\\\"id\\\"])\\n\\n                # If the caller had an exception, link this event as part of the exception chain\\n                if caller_id in exception_nodes:\\n                    self.graph.add_edge(exception_nodes[caller_id], event[\\\"id\\\"])\"}], \"iterate_graph\": [{\"file_path\": \"serverside/src/utils/call_graph.py\", \"line_start\": 54, \"line_end\": 61, \"content\": \"    def iterate_graph(self) -> None:\\n        \\\"\\\"\\\"Iterates through the graph, printing details of each node and its successors.\\\"\\\"\\\"\\n        for node, attrs in self.graph.nodes(data=True):\\n            function_name = attrs[\\\"function\\\"]\\n            file_line = attrs[\\\"file_line\\\"]\\n            tag = attrs[\\\"tag\\\"]\\n            successors = \\\", \\\".join(self.graph.nodes[succ][\\\"function\\\"] for succ in self.graph.successors(node))\\n            logging.info(f\\\"Function: {function_name} ({file_line}, {tag}) -> {successors or 'No outgoing calls'}\\\")\"}], \"export_for_graphviz\": [{\"file_path\": \"serverside/src/utils/call_graph.py\", \"line_start\": 63, \"line_end\": 67, \"content\": \"    def export_for_graphviz(self) -> None:\\n        \\\"\\\"\\\"Exports the graph in a format compatible with Graphviz.\\\"\\\"\\\"\\n        nodes = [(node, self.graph.nodes[node]) for node in self.graph.nodes()]\\n        edges = list(self.graph.edges())\\n        return nodes, edges\"}], \"find_node_by_fname\": [{\"file_path\": \"serverside/src/utils/call_graph.py\", \"line_start\": 69, \"line_end\": 75, \"content\": \"    def find_node_by_fname(self, function_name: str) -> list[any]:\\n        \\\"\\\"\\\"Finds nodes that correspond to a given function name.\\\"\\\"\\\"\\n        matching_nodes = []\\n        for node, attrs in self.graph.nodes(data=True):\\n            if attrs[\\\"function\\\"] == function_name:\\n                matching_nodes.append(node)\\n        return matching_nodes\"}], \"draw\": [{\"file_path\": \"serverside/src/utils/call_graph.py\", \"line_start\": 77, \"line_end\": 104, \"content\": \"    def draw(self, output_filename=\\\"func_call_graph\\\"):\\n        from graphviz import Digraph\\n\\n        dot = Digraph(comment=\\\"Function Call Graph\\\")\\n        color_mapping = {\\\"STDLIB\\\": \\\"gray\\\", \\\"LIBRARY\\\": \\\"blue\\\", \\\"INTERNAL\\\": \\\"white\\\"}\\n\\n        nodes = [(node, self.graph.nodes[node]) for node in self.graph.nodes()]\\n        edges = list(self.graph.edges())\\n\\n        for node, attrs in nodes:\\n            tag = attrs[\\\"tag\\\"]\\n            node_color = color_mapping.get(\\\"EXCEPTION\\\" if attrs[\\\"exception\\\"] else tag, \\\"white\\\")\\n\\n            label_parts = [\\n                f\\\"Function: {attrs['function']}\\\",\\n                f\\\"Tag: {tag}\\\",\\n                f\\\"Arguments: {json.dumps(attrs.get('arguments', {}), indent=2)}\\\",\\n                f\\\"Returns: {json.dumps(attrs.get('return_value', {}), indent=2)}\\\",\\n                f\\\"Did Raise: {attrs.get('did_raise', {})}\\\",\\n                f\\\"Traceback: {attrs.get('unhandled_exception', {})}\\\",\\n            ]\\n\\n            dot.node(node, label=\\\"\\\\n\\\".join(label_parts), style=\\\"filled\\\", fillcolor=node_color)\\n\\n        for u, v in edges:\\n            dot.edge(u, v)\\n\\n        dot.render(output_filename, view=True)\"}], \"_generate_jwt\": [{\"file_path\": \"serverside/src/utils/docker_executor.py\", \"line_start\": 43, \"line_end\": 50, \"content\": \"    def _generate_jwt(self, app_id, private_key):\\n        payload = {\\n            \\\"iat\\\": int(time.time()) - 60,  # Issued at time\\n            \\\"exp\\\": int(time.time()) + 600,  # JWT expiration time\\n            \\\"iss\\\": app_id,\\n        }\\n        token = jwt.encode(payload, private_key, algorithm=\\\"RS256\\\")\\n        return token\"}], \"_get_installation_access_token\": [{\"file_path\": \"serverside/src/utils/docker_executor.py\", \"line_start\": 52, \"line_end\": 56, \"content\": \"    def _get_installation_access_token(self, installation_id, jwt):\\n        headers = {\\\"Authorization\\\": f\\\"Bearer {jwt}\\\", \\\"Accept\\\": \\\"application/vnd.github.v3+json\\\"}\\n        url = f\\\"https://api.github.com/app/installations/{installation_id}/access_tokens\\\"\\n        response = requests.post(url, headers=headers)\\n        return response.json()[\\\"token\\\"]\"}], \"_clone_repository\": [{\"file_path\": \"serverside/src/utils/docker_executor.py\", \"line_start\": 58, \"line_end\": 63, \"content\": \"    def _clone_repository(self, repo_url: str, access_token: str, output_path: Path):\\n        # Modify the repo URL to include the access token\\n        auth_repo_url = repo_url.replace(\\\"https://\\\", f\\\"https://x-access-token:{access_token}@\\\")\\n        cmd = f\\\"git clone {auth_repo_url} {output_path}\\\"\\n        logging.info(f\\\"Running command: {cmd}\\\")\\n        subprocess.run(cmd.split(\\\" \\\"))\"}], \"_build_container\": [{\"file_path\": \"serverside/src/utils/docker_executor.py\", \"line_start\": 65, \"line_end\": 68, \"content\": \"    def _build_container(self, tag: str, repo_path: Path):\\n        cmd = f'docker build -f {repo_path / \\\"Dockerfile.cf\\\"} -t {tag} {repo_path}'\\n        logging.info(f\\\"Running cmd: {cmd}\\\")\\n        subprocess.run(cmd.split(\\\" \\\"))\"}], \"_run_tests_and_get_coverage\": [{\"file_path\": \"serverside/src/utils/docker_executor.py\", \"line_start\": 70, \"line_end\": 88, \"content\": \"    def _run_tests_and_get_coverage(self, tag: str) -> PytestOutput:\\n        # TODO: It's temporary fix, will think about it later.\\n        cmd = f'docker run -t {tag} /bin/bash -c \\\"cd serverside && pytest --cov=. --cov-report json >pytest_output; cat coverage.json; echo \\\"{self.SPLIT_TOKEN}\\\"; cat pytest_output;\\\"'\\n        logging.info(f\\\"Running cmd: {cmd}\\\")\\n        proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, shell=True)\\n\\n        cmd_output = proc.stdout.read().decode(\\\"utf-8\\\")\\n        coverage_output, pytest_raw_output = cmd_output.split(self.SPLIT_TOKEN)\\n        coverage_output = json.loads(coverage_output)\\n\\n        # TODO: This is temporary solution for testing.\\n        test_coverage = {\\n            f\\\"serverside/{key}\\\": TestCoverageItem(\\n                coverage=float(info_dict[\\\"summary\\\"][\\\"percent_covered\\\"]), missing_lines=list(info_dict[\\\"missing_lines\\\"])\\n            )\\n            for key, info_dict in coverage_output[\\\"files\\\"].items()\\n        }\\n\\n        return PytestOutput(test_coverage=test_coverage, pytest_raw_output=pytest_raw_output)\"}], \"_create_files\": [{\"file_path\": \"serverside/src/utils/docker_executor.py\", \"line_start\": 90, \"line_end\": 95, \"content\": \"    def _create_files(self, repo_dir: Path, new_files: dict[str, str]):\\n        for file_path, contents in new_files.items():\\n            # TODO: This is done temporarily, will change it later to properly copy it to docker.\\n            with open(repo_dir / file_path, \\\"w\\\") as f:\\n                logging.info(f\\\"Creating new file at: {repo_dir / file_path}\\\")\\n                f.write(contents)\"}], \"execute_with_new_files\": [{\"file_path\": \"serverside/src/utils/docker_executor.py\", \"line_start\": 97, \"line_end\": 125, \"content\": \"    def execute_with_new_files(self, new_files: dict[str, str]) -> PytestOutput:\\n        \\\"\\\"\\\"\\n        new_files:\\n            {\\n                '/path/to/new/test_1': 'def test_blah():\\\\n  return True',\\n                '/path/to/new/test_2': 'def test_blah2():\\\\n  return True',\\n            }\\n\\n        gh_repo.clone_repo()\\n        run tests from command with coverage\\n        return PytestOutput\\n        \\\"\\\"\\\"\\n        APP_ID = GITHUB_APP_ID\\n        PRIVATE_KEY = base64.b64decode(GITHUB_APP_PRIVATE_KEY_BASE64).decode(\\\"utf-8\\\")\\n        installation = self.repo_helper.get_installation_by_url(self.repo_url)\\n\\n        jwt_key = self._generate_jwt(APP_ID, PRIVATE_KEY)\\n        access_token = self._get_installation_access_token(installation.id, jwt_key)\\n\\n        with tempfile.TemporaryDirectory(dir=Path.cwd()) as repo_dir:\\n            logging.info(f\\\"Created temporary directory to clone repo: {repo_dir}\\\")\\n            self._clone_repository(self.repo_url, access_token, output_path=repo_dir)\\n            if len(new_files) > 0:\\n                self._create_files(Path(repo_dir), new_files)\\n            tag = str(uuid4()).split(\\\"-\\\")[0]\\n            self._build_container(tag=tag, repo_path=Path(repo_dir))\\n\\n            pytest_output = self._run_tests_and_get_coverage(tag=tag)\\n            return pytest_output\"}], \"main\": [{\"file_path\": \"serverside/src/utils/docker_executor.py\", \"line_start\": 128, \"line_end\": 136, \"content\": \"def main():\\n    docker_executor = DockerExecutor(\\\"https://github.com/CaptureFlow/captureflow-py\\\")\\n    # Valid input\\n    pytest_output = docker_executor.execute_with_new_files({\\\"serverside/tests/test_a.py\\\": \\\"print(1)\\\"})\\n    print(pytest_output.test_coverage)\\n\\n    # Invalid input\\n    pytest_output = docker_executor.execute_with_new_files({\\\"serverside/tests/test_a.py\\\": \\\"ppprint(1)\\\"})\\n    print(pytest_output.test_coverage)\"}], \"run\": [{\"file_path\": \"serverside/src/utils/exception_patcher.py\", \"line_start\": 22, \"line_end\": 71, \"content\": \"    def run(self):\\n        graphs = self.build_graphs_from_redis()\\n        self.enrich_graphs_with_github_context(graphs)\\n\\n        # Here we need to fetch top-level exception node details\\n        #   + all nodes that also propagated the exception\\n        #       + input_values\\n        #   + N parent node levels for context\\n        #       + input_valuess\\n        #   + M child node levels for context\\n        #       + input_values\\n        for graph in graphs:\\n            exception_chains = self.select_exception_sequences(graph)\\n\\n            if not exception_chains:\\n                logger.info(\\\"No exception chains found in this graph.\\\")\\n                continue\\n            else:\\n                logger.info(f\\\"Found a graph that contained unhandled exception chain {exception_chains}\\\")\\n\\n            for exception_chain in exception_chains:\\n\\n                context = self.fetch_exception_context(graph, exception_chain)\\n\\n                prompt = self.generate_fix_prompt_based_on_context(context)\\n                gpt_response = self.gpt_helper.call_chatgpt(prompt)\\n\\n                try:\\n                    json_str = self.extract_json_simple(gpt_response)\\n                    if json_str:\\n                        gpt_response_dict = json.loads(json_str)\\n                        change_reasoning = gpt_response_dict.get(\\\"change_reasoning\\\", \\\"\\\")\\n                        function_name = gpt_response_dict.get(\\\"function_name\\\", \\\"\\\")\\n                        code_block = self.gpt_helper.extract_first_code_block(gpt_response)\\n\\n                        matched_node_ids = graph.find_node_by_fname(function_name)\\n                        if matched_node_ids:\\n                            matches_node_id = matched_node_ids[0]\\n\\n                            self.repo_helper.create_pull_request_with_new_function(\\n                                graph.graph.nodes[matches_node_id],\\n                                context,\\n                                code_block,\\n                                change_reasoning,\\n                                self.gpt_helper,\\n                            )\\n                    else:\\n                        logger.error(\\\"Failed to extract JSON from GPT response.\\\")\\n                except (json.JSONDecodeError, KeyError) as e:\\n                    logger.exception(f\\\"Error processing GPT response: {e}\\\")\"}, {\"file_path\": \"serverside/src/utils/test_creator.py\", \"line_start\": 23, \"line_end\": 53, \"content\": \"    def run(self):\\n        graphs = self.build_graphs_from_redis()\\n        for graph in graphs:\\n            self.repo_helper.enrich_callgraph_with_github_context(graph)\\n            entry_point_node_id = self.select_function_to_cover(graph)\\n            if entry_point_node_id is None:\\n                logger.info(\\\"No entry point function was selected for coverage.\\\")\\n                continue\\n\\n            all_interactions = []  # Stores GPT-friendly info regarding what interactions are likely external (DBs/APIs)\\n            function_context = (\\n                []\\n            )  # Stores GPT-friendly info regarding what CallGraph nodes are doing (implementation, filename, etc)\\n            self.analyze_graph_for_interactions_and_context(\\n                graph, entry_point_node_id, all_interactions, function_context\\n            )\\n\\n            test_prompt = self.generate_test_prompt(function_context, all_interactions, graph, entry_point_node_id)\\n            gpt_response = self.gpt_helper.call_chatgpt(test_prompt)\\n            pytest_full_code = self.gpt_helper.extract_first_code_block(gpt_response)\\n\\n            if pytest_full_code:\\n                logger.info(\\n                    f\\\"Generated full pytest code for {graph.graph.nodes[entry_point_node_id]['function']}:\\\\n{pytest_full_code}\\\"\\n                )\\n                test_file_name = f\\\"captureflow_tests/test_{graph.graph.nodes[entry_point_node_id]['function'].replace(' ', '_').lower()}.py\\\"\\n                self.repo_helper.create_pull_request_with_test(\\n                    test_file_name, pytest_full_code, graph.graph.nodes[entry_point_node_id][\\\"function\\\"]\\n                )\\n            else:\\n                logger.error(\\\"Failed to generate valid full pytest code.\\\")\"}], \"extract_json_simple\": [{\"file_path\": \"serverside/src/utils/exception_patcher.py\", \"line_start\": 73, \"line_end\": 79, \"content\": \"    def extract_json_simple(self, text):\\n        try:\\n            start_index, end_index = text.index(\\\"{\\\"), text.rindex(\\\"}\\\") + 1\\n            json_str = text[start_index:end_index]\\n            return json_str\\n        except ValueError:\\n            return None\"}], \"build_graphs_from_redis\": [{\"file_path\": \"serverside/src/utils/exception_patcher.py\", \"line_start\": 81, \"line_end\": 89, \"content\": \"    def build_graphs_from_redis(self) -> List[CallGraph]:\\n        graphs = []\\n        search_pattern = f\\\"{self.repo_url}:*\\\"\\n        for key in self.redis_client.scan_iter(match=search_pattern):\\n            log_data_json = self.redis_client.get(key)\\n            if log_data_json:\\n                log_data = json.loads(log_data_json.decode(\\\"utf-8\\\"))\\n                graphs.append(CallGraph(json.dumps(log_data)))\\n        return graphs\"}, {\"file_path\": \"serverside/src/utils/test_creator.py\", \"line_start\": 55, \"line_end\": 63, \"content\": \"    def build_graphs_from_redis(self) -> List[CallGraph]:\\n        graphs = []\\n        search_pattern = f\\\"{self.repo_url}:*\\\"\\n        for key in self.redis_client.scan_iter(match=search_pattern):\\n            log_data_json = self.redis_client.get(key)\\n            if log_data_json:\\n                log_data = json.loads(log_data_json.decode(\\\"utf-8\\\"))\\n                graphs.append(CallGraph(json.dumps(log_data)))\\n        return graphs\"}], \"enrich_graphs_with_github_context\": [{\"file_path\": \"serverside/src/utils/exception_patcher.py\", \"line_start\": 91, \"line_end\": 93, \"content\": \"    def enrich_graphs_with_github_context(self, graphs: List[CallGraph]):\\n        for graph in graphs:\\n            self.repo_helper.enrich_callgraph_with_github_context(graph)\"}], \"select_exception_sequences\": [{\"file_path\": \"serverside/src/utils/exception_patcher.py\", \"line_start\": 95, \"line_end\": 159, \"content\": \"    def select_exception_sequences(self, graph: CallGraph) -> List[List[str]]:\\n        \\\"\\\"\\\"\\n        Collects sequences of nodes involved in the propagation of the same exception type.\\n        It identifies nodes where exceptions were raised and follows the propagation path \\n        through adjacent nodes sharing the same exception type, forming sequences.\\n\\n        Example:\\n            Consider a function call graph where arrows indicate the call direction, and nodes are labeled \\n            with their function names. Nodes with exceptions have an asterisk (*) next to them, \\n            and the exception type is indicated in brackets.\\n\\n                      a\\n                      |\\n                      b* [Exception X]\\n                    /   \\\\\\n                    c    d* [Exception X]\\n                    |\\n                    e\\n\\n            The exception chain we want to extract is [b*, d*]\\n\\n        Args:\\n            graph (CallGraph): The graph containing nodes with exception information.\\n\\n        Returns:\\n            List[List[str]]: Lists of node ID sequences. Each list represents a chain of\\n                            exception propagation for a specific exception type within the graph.\\n        \\\"\\\"\\\"\\n        exception_sequences = []\\n\\n        # Identify nodes where exceptions were raised.\\n        raised_exception_nodes = [\\n            (node_id, data) for node_id, data in graph.graph.nodes(data=True) if data.get(\\\"did_raise\\\")\\n        ]\\n        visited = set()\\n\\n        for start_node, start_data in raised_exception_nodes:\\n            if start_node in visited:\\n                continue\\n\\n            current_sequence = [start_node]\\n            visited.add(start_node)\\n\\n            # Adjacent nodes with same exception_type => part of same exception propagation chain\\n            start_exception_type = start_data[\\\"unhandled_exception\\\"][\\\"type\\\"]\\n\\n            for neighbor in list(graph.graph.predecessors(start_node)) + list(graph.graph.successors(start_node)):\\n                if neighbor in visited:\\n                    continue\\n\\n                neighbor_data = graph.graph.nodes[neighbor]\\n                if (\\n                    neighbor_data.get(\\\"did_raise\\\")\\n                    and neighbor_data[\\\"unhandled_exception\\\"][\\\"type\\\"] == start_exception_type\\n                ):\\n                    current_sequence.append(neighbor)\\n                    visited.add(neighbor)\\n\\n            # There are quite a lot if internal (invisible) exception chains happening inside libraries\\n            # There is no point in refactoring them => prune and skip if needed\\n            pruned_sequence = [node for node in current_sequence if graph.graph.nodes[node].get(\\\"tag\\\") != \\\"STDLIB\\\"]\\n            if len(pruned_sequence) >= 1:\\n                exception_sequences.append(current_sequence)\\n\\n        return exception_sequences\"}], \"fetch_exception_context\": [{\"file_path\": \"serverside/src/utils/exception_patcher.py\", \"line_start\": 161, \"line_end\": 213, \"content\": \"    def fetch_exception_context(self, graph: CallGraph, exception_chain: List[str]) -> Dict[str, Any]:\\n        \\\"\\\"\\\"\\n        Gathers contextual information for nodes involved in exception propagation, including details\\n        about the exception nodes, and any relevant context from non-exceptional ancestors and descendants.\\n\\n        Example:\\n            Given an exception propagating from 'b' to 'd' in the following call graph:\\n\\n                          a\\n                          |\\n                          b* [Exception X]\\n                        /   \\\\\\n                       c     d* [Exception X]\\n                       |\\n                       e\\n\\n            This method provides detailed context for the exception chain ['b*', 'd*'], \\n            and includes information about 'a', 'c' for a comprehensive view.\\n\\n        Args:\\n            graph (CallGraph): The call graph object containing nodes, function calls, and exception information.\\n            exception_chain (List[str]): A list of node IDs representing the sequence of exception propagation.\\n\\n        Returns:\\n            Dict[str, Any]: A dictionary with detailed context about each node in the exception chain,\\n                            including the node's details, immediate non-exceptional ancestors, and descendants.\\n                            This provides a holistic view of the functions leading to and affected by the exception.\\n        \\\"\\\"\\\"\\n        chain_context = {\\\"exception_nodes\\\": []}\\n\\n        for node_id in exception_chain:\\n            node_data = graph.graph.nodes[node_id]\\n            node_context = {\\n                \\\"node_details\\\": self.format_node_details(node_data, include_code=True),\\n                \\\"context_parents\\\": [],\\n                \\\"context_children\\\": [],\\n            }\\n\\n            # Add parents only if they are not part of the exception chain\\n            for parent_id in graph.graph.predecessors(node_id):\\n                if parent_id not in exception_chain:\\n                    parent_data = graph.graph.nodes[parent_id]\\n                    node_context[\\\"context_parents\\\"].append(self.format_node_details(parent_data, include_code=True))\\n\\n            # Add any children called by this node that are not part of the exception chain\\n            for child_id in graph.graph.successors(node_id):\\n                if child_id not in exception_chain:\\n                    child_data = graph.graph.nodes[child_id]\\n                    node_context[\\\"context_children\\\"].append(self.format_node_details(child_data, include_code=True))\\n\\n            chain_context[\\\"exception_nodes\\\"].append(node_context)\\n\\n        return chain_context\"}], \"format_node_details\": [{\"file_path\": \"serverside/src/utils/exception_patcher.py\", \"line_start\": 215, \"line_end\": 247, \"content\": \"    def format_node_details(self, node_data: Dict[str, Any], include_code: bool = False) -> Dict[str, Any]:\\n        \\\"\\\"\\\"\\n        Prepares detailed information of a node for further analysis.\\n\\n        This method differentiates between nodes that ended with an exception and those that\\n        completed execution normally, providing either exception details or return values accordingly.\\n\\n        Example output structure:\\n            {\\n                \\\"function_name\\\": \\\"example_function\\\",\\n                \\\"file_line\\\": \\\"example.py:42\\\",\\n                \\\"arguments\\\": {\\\"arg1\\\": \\\"value1\\\", \\\"arg2\\\": \\\"value2\\\"},\\n                \\\"exception_info\\\": {\\\"type\\\": \\\"ValueError\\\", \\\"value\\\": \\\"An error occurred\\\"},\\n                \\\"function_implementation\\\": \\\"def example_function(arg1, arg2): pass\\\",\\n                \\\"file_content\\\": \\\"def example_function(arg1, arg2): pass\\\\n...\\\"\\n            }\\n        \\\"\\\"\\\"\\n        details = {\\n            \\\"function_name\\\": node_data.get(\\\"function\\\"),\\n            \\\"file_line\\\": node_data.get(\\\"file_line\\\", \\\"unknown\\\"),\\n            \\\"arguments\\\": node_data.get(\\\"arguments\\\", {}),\\n            \\\"exception_info\\\": node_data.get(\\\"unhandled_exception\\\"),\\n            \\\"return_value\\\": node_data.get(\\\"return_value\\\"),\\n            \\\"function_implementation\\\": (\\n                node_data.get(\\\"github_function_implementation\\\").get(\\\"content\\\", \\\"Not available\\\")\\n                if isinstance(node_data.get(\\\"github_function_implementation\\\"), dict) and include_code\\n                else \\\"Not available\\\"\\n            ),\\n            \\\"file_content\\\": node_data.get(\\\"github_file_content\\\", \\\"Not available\\\") if include_code else None,\\n        }\\n\\n        # Clean up None values\\n        return {key: value for key, value in details.items() if value is not None}\"}], \"fetch_parents\": [{\"file_path\": \"serverside/src/utils/exception_patcher.py\", \"line_start\": 249, \"line_end\": 262, \"content\": \"    def fetch_parents(\\n        self, graph: CallGraph, node_id: str, depth: int, include_code: bool = False\\n    ) -> List[Dict[str, Any]]:\\n        \\\"\\\"\\\"\\n        Recursively fetches parent nodes up to a certain depth, including their code.\\n        \\\"\\\"\\\"\\n        if depth == 0:\\n            return []\\n        parents = []\\n        for predecessor in graph.graph.predecessors(node_id):\\n            parent_data = graph.graph.nodes[predecessor]\\n            parents.append(self.format_node_details(parent_data, include_code))\\n            parents.extend(self.fetch_parents(graph, predecessor, depth - 1, include_code))\\n        return parents\"}], \"fetch_children\": [{\"file_path\": \"serverside/src/utils/exception_patcher.py\", \"line_start\": 264, \"line_end\": 277, \"content\": \"    def fetch_children(\\n        self, graph: CallGraph, node_id: str, depth: int, include_code: bool = False\\n    ) -> List[Dict[str, Any]]:\\n        \\\"\\\"\\\"\\n        Recursively fetches child nodes up to a certain depth, including their code.\\n        \\\"\\\"\\\"\\n        if depth == 0:\\n            return []\\n        children = []\\n        for successor in graph.graph.successors(node_id):\\n            child_data = graph.graph.nodes[successor]\\n            children.append(self.format_node_details(child_data, include_code))\\n            children.extend(self.fetch_children(graph, successor, depth - 1, include_code))\\n        return children\"}], \"generate_fix_prompt_based_on_context\": [{\"file_path\": \"serverside/src/utils/exception_patcher.py\", \"line_start\": 279, \"line_end\": 343, \"content\": \"    def generate_fix_prompt_based_on_context(self, context: Dict[str, Any]) -> str:\\n        exception_chain_details = \\\"Exception Chain Analysis:\\\\nBelow is the sequence of functions leading to and including the exception, along with their inputs, outputs, and implementation details:\\\\n\\\"\\n\\n        for index, node_context in enumerate(context[\\\"exception_nodes\\\"]):\\n            node_details = node_context[\\\"node_details\\\"]\\n            is_last_node = index == len(context[\\\"exception_nodes\\\"]) - 1\\n\\n            function_header = (\\n                f\\\"\\\\n{'-'*20}\\\\nFunction: {node_details['function_name']} at {node_details['file_line']}\\\\n{'-'*20}\\\"\\n            )\\n            exception_info = (\\n                f\\\"Exception Type: {node_details['exception_info']['type']} - {node_details['exception_info']['value']}\\\"\\n            )\\n            inputs = f\\\"Inputs (serialization method described at the end):\\\\n{json.dumps(node_details['arguments'], indent=2, default=str)}\\\"\\n            outputs = (\\n                f\\\"Outputs:\\\\n{json.dumps(node_details.get('return_value', 'No return value'), indent=2, default=str)}\\\"\\n            )\\n            implementation = f\\\"Function Implementation:\\\\n```python\\\\n{node_details['function_implementation']}\\\\n```\\\"\\n\\n            node_summary = f\\\"{function_header}\\\\n{exception_info}\\\\n{inputs}\\\\n{outputs}\\\\n{implementation}\\\"\\n\\n            if is_last_node:\\n                node_summary += \\\"\\\\n(This function is where the exception was raised and propagated.)\\\"\\n\\n            additional_context_summary = \\\"\\\"\\n            if node_context[\\\"context_children\\\"]:\\n                additional_context_summary = \\\"\\\\nAdditional context from called functions:\\\\n\\\" + \\\"\\\\n\\\".join(\\n                    f\\\"- {child['function_name']} at {child['file_line']}:\\\\n  Inputs: {json.dumps(child['arguments'], indent=2, default=str)}\\\\n  Outputs: {json.dumps(child.get('return_value', 'No return value'), indent=2, default=str)}\\\\n  Implementation snippet:\\\\n```python\\\\n{child['function_implementation']}\\\\n```\\\"\\n                    for child in node_context[\\\"context_children\\\"]\\n                )\\n\\n            exception_chain_details += f\\\"{node_summary}{additional_context_summary}\\\\n\\\"\\n\\n        serialization_method_description = \\\"\\\"\\\"\\n            Serialization method for input/output values:\\n            ```python\\n            def _serialize_variable(self, value: Any) -> Dict[str, Any]:\\n                try:\\n                    json_value = json.dumps(value)\\n                except Exception as e:\\n                    json_value = str(value)\\n                return {\\\"python_type\\\": str(type(value)), \\\"json_serialized\\\": json_value}\\n            ```\\n        \\\"\\\"\\\"\\n\\n        formatting_commands = \\\"\\\"\\\"\\n            Please provide me two things: JSON of this form\\n            1. \\\"confidence\\\" that new code is going to resolve such exceptions (1 to 5)\\n            2. \\\"function_name\\\" that best to be updated to resolve exception.\\n            3. \\\"change_reasoning\\\" why do you think change is going to address exception.\\n            and new proposed function code right escaped with ```python ...``` after it.\\n            Here's example output:\\n            {\\n                \\\"confidence\\\": 5,\\n                \\\"function_name\\\": \\\"do_stuff\\\",\\n                \\\"change_reasoning\\\": \\\"to fix above exception the most correct thing is ...\\\"\\n            }\\n            ```python\\n            def do_stuff():\\n                pass # new implementation\\n            ```\\n        \\\"\\\"\\\"\\n\\n        prompt = f\\\"{exception_chain_details}\\\\n{serialization_method_description}\\\\n{formatting_commands}\\\"\\n        return prompt\"}], \"select_function_to_cover\": [{\"file_path\": \"serverside/src/utils/test_creator.py\", \"line_start\": 65, \"line_end\": 71, \"content\": \"    def select_function_to_cover(self, graph: CallGraph) -> Optional[str]:\\n        # Select the first non-stdlib node as the entry point for testing.\\n        # TODO: Replace with a way to get endpoint\\n        for node_id, data in graph.graph.nodes(data=True):\\n            if data.get(\\\"tag\\\") != \\\"STDLIB\\\":\\n                return node_id\\n        return None\"}], \"analyze_external_interactions_with_chatgpt\": [{\"file_path\": \"serverside/src/utils/test_creator.py\", \"line_start\": 73, \"line_end\": 100, \"content\": \"    def analyze_external_interactions_with_chatgpt(self, node_data: Dict[str, Any]) -> List[Dict[str, Any]]:\\n        function_implementation = node_data.get(\\\"github_function_implementation\\\", {}).get(\\\"content\\\", \\\"Not available\\\")\\n        json_example = {\\n            \\\"interactions\\\": [\\n                {\\n                    \\\"type\\\": \\\"DB_INTERACTION | API_CALL\\\",\\n                    \\\"details\\\": \\\"Query to SQLite database for user data at line 14\\\",\\n                    \\\"mock_idea\\\": 'with patch(\\\"sqlite3.connect\\\") as mock_connect: mock_cursor = mock_connect.return_value.cursor.return_value; mock_cursor.fetchall.return_value = [(10,), (20,)]',\\n                    \\\"certainty\\\": \\\"high\\\",\\n                }\\n            ]\\n        }\\n        prompt = (\\n            f\\\"Please analyze the provided Python code snippet to identify any external interactions such as database queries, \\\"\\n            f\\\"API calls, or file operations. For each detected interaction, return a JSON formatted list describing the interaction. \\\"\\n            f\\\"Each interaction should include the type, detailed description, and suggested mocking strategy if applicable. \\\"\\n            f\\\"Please classify the certainty of each interaction as 'high', 'medium', or 'low'. Based on the certainty, \\\"\\n            f\\\"provide appropriate mock ideas or indicate if mocking is not certain. Use the following response format:\\\\n\\\"\\n            f\\\"{json.dumps(json_example, indent=2)}\\\\n\\\"\\n            f\\\"If no external interactions are detected, please return an empty interactions array.\\\\n\\\"\\n            f\\\"Additionally, indicate the specific functions where these interactions occur.\\\\n\\\\n\\\"\\n            f\\\"```python\\\\n{function_implementation}\\\\n```\\\"\\n        )\\n\\n        # Call ChatGPT and get the response\\n        response = self.gpt_helper.call_chatgpt(prompt)\\n        interactions = self.parse_interaction_response(response)\\n        return interactions\"}], \"parse_interaction_response\": [{\"file_path\": \"serverside/src/utils/test_creator.py\", \"line_start\": 102, \"line_end\": 111, \"content\": \"    def parse_interaction_response(self, response: str) -> List[Dict[str, Any]]:\\n        try:\\n            start_index = response.index(\\\"{\\\")\\n            end_index = response.rindex(\\\"}\\\") + 1\\n            json_str = response[start_index:end_index]\\n            interaction_data = json.loads(json_str)\\n            return interaction_data.get(\\\"interactions\\\", [])\\n        except (ValueError, json.JSONDecodeError) as e:\\n            logger.error(f\\\"Failed to decode interaction response from ChatGPT: {e}\\\")\\n            return []\"}], \"analyze_graph_for_interactions_and_context\": [{\"file_path\": \"serverside/src/utils/test_creator.py\", \"line_start\": 113, \"line_end\": 132, \"content\": \"    def analyze_graph_for_interactions_and_context(\\n        self, graph: CallGraph, node_id: str, interactions: List[Dict[str, Any]], function_context: List[str]\\n    ):\\n        node_data = graph.graph.nodes[node_id]\\n        if (\\n            node_data[\\\"tag\\\"] == \\\"STDLIB\\\"\\n            or \\\"github_function_implementation\\\" not in node_data\\n            or node_data[\\\"github_function_implementation\\\"] == \\\"not_found\\\"\\n        ):\\n            return\\n\\n        node_interactions = self.analyze_external_interactions_with_chatgpt(node_data)\\n        interactions.extend(node_interactions)\\n\\n        function_context.append(\\n            f\\\"Function '{node_data['function']}' defined in '{node_data.get('github_file_path', 'unknown')}' at line {node_data.get('github_function_implementation', {}).get('start_line', 'unknown')} with this implementation {node_data.get('github_function_implementation', {}).get('content', 'Not available')} should consider the following details for mocking (if needed at all): {json.dumps(node_interactions)}\\\"\\n        )\\n\\n        for successor in graph.graph.successors(node_id):\\n            self.analyze_graph_for_interactions_and_context(graph, successor, interactions, function_context)\"}], \"generate_test_prompt\": [{\"file_path\": \"serverside/src/utils/test_creator.py\", \"line_start\": 134, \"line_end\": 177, \"content\": \"    def generate_test_prompt(self, function_context, all_interactions, graph, entry_point_node_id):\\n        entry_point_data = graph.graph.nodes[entry_point_node_id]\\n\\n        # Load the pytest template from the resources directory\\n        template_path = os.path.join(os.path.dirname(__file__), \\\"resources\\\", \\\"pytest_template.py\\\")\\n        with open(template_path, \\\"r\\\") as file:\\n            pytest_template = file.read()\\n\\n        # Generate mock instructions only for high-certainty interactions\\n        mock_instructions = \\\"\\\\n\\\".join(\\n            interaction[\\\"mock_idea\\\"]\\n            for interaction in all_interactions\\n            if interaction.get(\\\"certainty\\\", \\\"low\\\") == \\\"high\\\" and \\\"mock_idea\\\" in interaction\\n        )\\n\\n        function_name = entry_point_data[\\\"function\\\"]\\n        file_path = entry_point_data.get(\\\"github_file_path\\\", \\\"unknown\\\")\\n        line_number = entry_point_data.get(\\\"github_function_implementation\\\", {}).get(\\\"start_line\\\", \\\"unknown\\\")\\n        function_implementation = entry_point_data.get(\\\"github_function_implementation\\\", {}).get(\\n            \\\"content\\\", \\\"Not available\\\"\\n        )\\n        full_function_content = entry_point_data.get(\\n            \\\"github_file_content\\\", \\\"Function content not available\\\"\\n        )  # Retrieve full function content\\n        arguments = json.dumps(entry_point_data.get(\\\"arguments\\\", {}), indent=2)\\n        expected_output = entry_point_data[\\\"return_value\\\"].get(\\\"json_serialized\\\", \\\"No output captured\\\")\\n        context_details = \\\"\\\\n\\\".join(function_context)\\n\\n        prompt = (\\n            f\\\"Write a complete pytest file for testing the WSGI app entry point '{function_name}' defined in '{file_path}' at line {line_number}. \\\"\\n            f\\\"Full function implementation from the source file:\\\\n{full_function_content}\\\\n\\\"\\n            f\\\"Function implementation snippet:\\\\n{function_implementation}\\\\n\\\"\\n            f\\\"Arguments: {arguments}\\\\n\\\"\\n            f\\\"Expected output: {expected_output}\\\\n\\\"\\n            \\\"Context and external interactions:\\\\n\\\"\\n            f\\\"{context_details}\\\\n\\\"\\n            \\\"External interactions to mock (follow the instructions below):\\\\n\\\"\\n            f\\\"{mock_instructions}\\\\n\\\"\\n            f\\\"\\\\n# --- Start of the Pytest Template ---\\\\n{pytest_template}\\\\n# --- End of the Pytest Template ---\\\\n\\\"\\n            \\\"Include necessary imports, setup any needed fixtures, and define test functions with assertions based on the expected output. \\\"\\n            \\\"Ensure the test file adheres to Python best practices and pytest conventions.\\\"\\n        )\\n\\n        return prompt\"}], \"load_sample_trace\": [{\"file_path\": \"serverside/tests/integration/basic_flow.py\", \"line_start\": 7, \"line_end\": 10, \"content\": \"def load_sample_trace():\\n    trace_path = Path(__file__).parent.parent / \\\"assets\\\" / \\\"sample_trace.json\\\"\\n    with open(trace_path) as f:\\n        return json.load(f)\"}], \"test_store_traces_and_generate_mr\": [{\"file_path\": \"serverside/tests/integration/basic_flow.py\", \"line_start\": 17, \"line_end\": 34, \"content\": \"def test_store_traces_and_generate_mr():\\n    sample_trace_1 = load_sample_trace()\\n    sample_trace_2 = load_sample_trace()\\n\\n    # Store\\n    response_1 = requests.post(f\\\"{BASE_URL}/traces\\\", params={\\\"repository-url\\\": REPO_URL}, json=sample_trace_1)\\n    assert response_1.status_code == 200\\n    assert response_1.json()[\\\"message\\\"] == \\\"Trace log saved successfully\\\"\\n\\n    # Store\\n    response_2 = requests.post(f\\\"{BASE_URL}/traces\\\", params={\\\"repository-url\\\": REPO_URL}, json=sample_trace_2)\\n    assert response_2.status_code == 200\\n    assert response_2.json()[\\\"message\\\"] == \\\"Trace log saved successfully\\\"\\n\\n    # Generate\\n    response_mr = requests.post(f\\\"{BASE_URL}/merge-requests\\\", params={\\\"repository-url\\\": REPO_URL})\\n    assert response_mr.status_code == 200\\n    assert response_mr.json()[\\\"message\\\"] == \\\"MR generation process started successfully\\\"\"}], \"test_call_graph_build\": [{\"file_path\": \"serverside/tests/utils/test_call_graph.py\", \"line_start\": 16, \"line_end\": 30, \"content\": \"def test_call_graph_build(sample_trace):\\n    call_graph = CallGraph(json.dumps(sample_trace))\\n\\n    assert call_graph.graph.number_of_nodes() > 0\\n    assert call_graph.graph.number_of_edges() > 0\\n\\n    # Assert specific function presence and properties\\n    function_nodes = call_graph.find_node_by_fname(\\\"calculate_avg\\\")\\n    assert function_nodes\\n\\n    for node_id in function_nodes:\\n        node = call_graph.graph.nodes[node_id]\\n        assert node[\\\"function\\\"] == \\\"calculate_avg\\\"\\n        assert \\\"arguments\\\" in node\\n        assert \\\"return_value\\\" in node\"}], \"test_call_graph_build_and_tags\": [{\"file_path\": \"serverside/tests/utils/test_call_graph.py\", \"line_start\": 33, \"line_end\": 53, \"content\": \"def test_call_graph_build_and_tags(sample_trace):\\n    call_graph = CallGraph(json.dumps(sample_trace))\\n\\n    assert call_graph.graph.number_of_nodes() > 0\\n    assert call_graph.graph.number_of_edges() > 0\\n\\n    internal_nodes = call_graph.find_node_by_fname(\\\"calculate_avg\\\")\\n    stdlib_nodes = call_graph.find_node_by_fname(\\\"iscoroutinefunction\\\")\\n\\n    # Ensure we found the nodes\\n    assert internal_nodes\\n    assert stdlib_nodes\\n\\n    # Check we are able to differentiate between INTERNAL (interesting modules) and LIB modules (not-so-interesting)\\n    for node_id in internal_nodes:\\n        node = call_graph.graph.nodes[node_id]\\n        assert node[\\\"tag\\\"] == \\\"INTERNAL\\\", f\\\"Node {node_id} expected to be INTERNAL, got {node['tag']}\\\"\\n\\n    for node_id in stdlib_nodes:\\n        node = call_graph.graph.nodes[node_id]\\n        assert node[\\\"tag\\\"] == \\\"STDLIB\\\", f\\\"Node {node_id} expected to be STDLIB, got {node['tag']}\\\"\"}], \"disable_network_access\": [{\"file_path\": \"serverside/tests/utils/test_creator.py\", \"line_start\": 13, \"line_end\": 17, \"content\": \"def disable_network_access():\\n    with patch(\\\"socket.socket\\\") as mock_socket, patch(\\\"socket.create_connection\\\") as mock_create_conn:\\n        mock_socket.side_effect = Exception(\\\"Network access not allowed during tests!\\\")\\n        mock_create_conn.side_effect = Exception(\\\"Network access not allowed during tests!\\\")\\n        yield\"}, {\"file_path\": \"serverside/tests/utils/test_exception_patcher.py\", \"line_start\": 13, \"line_end\": 25, \"content\": \"def disable_network_access():\\n    def guard(*args, **kwargs):\\n        raise Exception(\\\"Network access not allowed during tests!\\\")\\n\\n    orig_socket = socket.socket\\n    orig_create_connection = socket.create_connection\\n    socket.socket = guard\\n    socket.create_connection = guard\\n\\n    yield\\n\\n    socket.socket = orig_socket\\n    socket.create_connection = orig_create_connection\"}], \"sample_trace_json\": [{\"file_path\": \"serverside/tests/utils/test_creator.py\", \"line_start\": 21, \"line_end\": 24, \"content\": \"def sample_trace_json():\\n    trace_path = Path(__file__).parent.parent / \\\"assets\\\" / \\\"sample_trace.json\\\"\\n    with open(trace_path) as f:\\n        return json.load(f)\"}, {\"file_path\": \"serverside/tests/utils/test_exception_patcher.py\", \"line_start\": 29, \"line_end\": 32, \"content\": \"def sample_trace_json():\\n    trace_path = Path(__file__).parent.parent / \\\"assets\\\" / \\\"sample_trace_with_exception.json\\\"\\n    with open(trace_path) as f:\\n        return json.load(f)\"}], \"mock_redis_client\": [{\"file_path\": \"serverside/tests/utils/test_creator.py\", \"line_start\": 28, \"line_end\": 33, \"content\": \"def mock_redis_client(sample_trace_json):\\n    with patch(\\\"redis.Redis\\\") as MockRedis:\\n        mock_redis = MockRedis()\\n        mock_redis.scan_iter.return_value = [\\\"key:1\\\"]\\n        mock_redis.get.return_value = json.dumps(sample_trace_json).encode(\\\"utf-8\\\")\\n        yield mock_redis\"}, {\"file_path\": \"serverside/tests/utils/test_exception_patcher.py\", \"line_start\": 36, \"line_end\": 41, \"content\": \"def mock_redis_client(sample_trace_json):\\n    with patch(\\\"redis.Redis\\\") as MockRedis:\\n        mock_redis_client = MockRedis()\\n        mock_redis_client.scan_iter.return_value = [f\\\"key:{i}\\\" for i in range(3)]\\n        mock_redis_client.get.side_effect = lambda k: json.dumps(sample_trace_json).encode(\\\"utf-8\\\")\\n        yield mock_redis_client\"}], \"github_data_mapping\": [{\"file_path\": \"serverside/tests/utils/test_creator.py\", \"line_start\": 55, \"line_end\": 66, \"content\": \"def github_data_mapping():\\n    return {\\n        \\\"calculate_average\\\": {\\n            \\\"github_file_path\\\": \\\"/path/to/function.py\\\",\\n            \\\"github_function_implementation\\\": {\\n                \\\"start_line\\\": 10,\\n                \\\"end_line\\\": 20,\\n                \\\"content\\\": \\\"def calculate_average(): pass\\\",\\n            },\\n            \\\"github_file_content\\\": \\\"import numpy\\\\ndef calculcate_average(): pass\\\",\\n        }\\n    }\"}, {\"file_path\": \"serverside/tests/utils/test_exception_patcher.py\", \"line_start\": 66, \"line_end\": 86, \"content\": \"def github_data_mapping():\\n    return {\\n        \\\"calculate_average\\\": {\\n            \\\"github_file_path\\\": \\\"/path/to/calculate_average.py\\\",\\n            \\\"github_function_implementation\\\": {\\n                \\\"start_line\\\": 1,\\n                \\\"end_line\\\": 5,\\n                \\\"content\\\": \\\"def calculate_average(): pass\\\",\\n            },\\n            \\\"github_file_content\\\": \\\"import numpy\\\\ndef calculate_average(): pass\\\",\\n        },\\n        \\\"calculate_sum\\\": {\\n            \\\"github_file_path\\\": \\\"/path/to/calculate_sum.py\\\",\\n            \\\"github_function_implementation\\\": {\\n                \\\"start_line\\\": 1,\\n                \\\"end_line\\\": 5,\\n                \\\"content\\\": \\\"def calculate_sum(): pass\\\",\\n            },\\n            \\\"github_file_content\\\": \\\"import numpy\\\\ndef calculate_sum(): pass\\\",\\n        },\\n    }\"}], \"mock_enrich_callgraph_with_github_context\": [{\"file_path\": \"serverside/tests/utils/test_creator.py\", \"line_start\": 71, \"line_end\": 77, \"content\": \"    def mock_enrich_callgraph_with_github_context(callgraph: CallGraph) -> None:\\n        for node_id in callgraph.graph.nodes:\\n            node = callgraph.graph.nodes[node_id]\\n            if \\\"function\\\" in node:\\n                enriched_node = github_data_mapping.get(node[\\\"function\\\"])\\n                if enriched_node:\\n                    callgraph.graph.nodes[node_id].update(enriched_node)\"}, {\"file_path\": \"serverside/tests/utils/test_exception_patcher.py\", \"line_start\": 91, \"line_end\": 97, \"content\": \"    def mock_enrich_callgraph_with_github_context(callgraph: CallGraph) -> None:\\n        for node_id in callgraph.graph.nodes:\\n            node = callgraph.graph.nodes[node_id]\\n            if \\\"function\\\" in node:\\n                enriched_node = github_data_mapping.get(node[\\\"function\\\"])\\n                if enriched_node:\\n                    callgraph.graph.nodes[node_id].update(enriched_node)\"}], \"test_test_coverage_creator_run\": [{\"file_path\": \"serverside/tests/utils/test_creator.py\", \"line_start\": 86, \"line_end\": 114, \"content\": \"def test_test_coverage_creator_run(mock_redis_client, mock_openai_helper, mock_repo_helper):\\n    with patch(\\\"src.utils.test_creator.RepoHelper\\\", return_value=mock_repo_helper), patch(\\n        \\\"src.utils.test_creator.OpenAIHelper\\\", return_value=mock_openai_helper\\n    ):\\n\\n        test_creator = TestCoverageCreator(redis_client=mock_redis_client, repo_url=\\\"http://sample.repo.url\\\")\\n        test_creator.run()\\n\\n        # Check interactions for each ChatGPT call\\n        interaction_call = mock_openai_helper.call_chatgpt.call_args_list[0]\\n        test_generation_call = mock_openai_helper.call_chatgpt.call_args_list[1]\\n\\n        assert (\\n            \\\"Please analyze the provided Python code snippet to identify any external interactions\\\"\\n            in interaction_call[0][0]\\n        )\\n        assert \\\"Write a complete pytest file\\\" in test_generation_call[0][0]\\n\\n        # Ensure the correct handling of responses\\n        assert mock_openai_helper.extract_first_code_block.called\\n        pytest_code = mock_openai_helper.extract_first_code_block.return_value\\n        assert \\\"def test_calculate_average(): assert True\\\" == pytest_code.strip()\\n\\n        # Check if enriched GitHub data & mocking hints were considered in the prompt\\n        assert (\\n            \\\"Write a complete pytest file for testing the WSGI app entry point 'calculate_average'\\\"\\n            in test_generation_call[0][0]\\n        )\\n        assert \\\"External interactions to mock (follow the instructions below):\\\\n\\\" in test_generation_call[0][0]\"}], \"guard\": [{\"file_path\": \"serverside/tests/utils/test_exception_patcher.py\", \"line_start\": 14, \"line_end\": 15, \"content\": \"    def guard(*args, **kwargs):\\n        raise Exception(\\\"Network access not allowed during tests!\\\")\"}], \"test_bug_orchestrator_run\": [{\"file_path\": \"serverside/tests/utils/test_exception_patcher.py\", \"line_start\": 106, \"line_end\": 142, \"content\": \"def test_bug_orchestrator_run(mock_redis_client, mock_openai_helper, mock_repo_helper):\\n    with patch(\\\"src.utils.exception_patcher.RepoHelper\\\", return_value=mock_repo_helper), patch(\\n        \\\"src.utils.exception_patcher.OpenAIHelper\\\", return_value=mock_openai_helper\\n    ):\\n        orchestrator = ExceptionPatcher(redis_client=mock_redis_client, repo_url=\\\"http://sample.repo.url\\\")\\n        orchestrator.run()\\n\\n        # Call arguments for mock_openai_helper.call_chatgpt\\n        actual_prompt = mock_openai_helper.call_chatgpt.call_args[0][0]\\n\\n        assert \\\"Exception Chain Analysis:\\\" in actual_prompt\\n        assert \\\"Function: calculate_average\\\" in actual_prompt\\n        assert \\\"Function: calculate_avg\\\" in actual_prompt\\n        assert \\\"ZeroDivisionError - division by zero\\\" in actual_prompt\\n        expected_function_implementation_snippets = [\\\"def calculate_average(): pass\\\", \\\"def calculate_sum(): pass\\\"]\\n        for snippet in expected_function_implementation_snippets:\\n            assert snippet in actual_prompt\\n\\n        # Validate the call to create_pull_request_with_new_function\\n        mock_repo_helper.create_pull_request_with_new_function.assert_called()\\n        called_args = mock_repo_helper.create_pull_request_with_new_function.call_args[0]\\n        node_arg = called_args[0]\\n\\n        # Validate key fields of the node argument\\n        assert node_arg.get(\\\"function\\\") == \\\"calculate_avg\\\"\\n        assert node_arg.get(\\\"did_raise\\\") is True\\n        assert node_arg.get(\\\"unhandled_exception\\\").get(\\\"type\\\") == \\\"ZeroDivisionError\\\"\\n        assert node_arg.get(\\\"unhandled_exception\\\").get(\\\"value\\\") == \\\"division by zero\\\"\\n\\n        # There are two exception nodes in sample trace json\\n        exception_context = called_args[1]\\n        assert len(exception_context[\\\"exception_nodes\\\"]) == 2\\n\\n        # New function code is exactly what mock ChatGPT returned\\n        new_function_code = called_args[2]\\n        expected_new_function_code = \\\"def dummy_function(): pass\\\"\\n        assert new_function_code.strip() == expected_new_function_code.strip()\"}], \"visit_ClassDef\": [{\"file_path\": \"serverside/src/utils/integrations/github_integration.py\", \"line_start\": 23, \"line_end\": 25, \"content\": \"    def visit_ClassDef(self, node):\\n        self.definitions.append((\\\"class\\\", node))\\n        self.generic_visit(node)\"}], \"visit_FunctionDef\": [{\"file_path\": \"serverside/src/utils/integrations/github_integration.py\", \"line_start\": 27, \"line_end\": 29, \"content\": \"    def visit_FunctionDef(self, node):\\n        self.definitions.append((\\\"function\\\", node))\\n        self.generic_visit(node)\"}], \"visit_AsyncFunctionDef\": [{\"file_path\": \"serverside/src/utils/integrations/github_integration.py\", \"line_start\": 31, \"line_end\": 33, \"content\": \"    def visit_AsyncFunctionDef(self, node):\\n        self.definitions.append((\\\"function\\\", node))\\n        self.generic_visit(node)\"}], \"_get_integration\": [{\"file_path\": \"serverside/src/utils/integrations/github_integration.py\", \"line_start\": 43, \"line_end\": 46, \"content\": \"    def _get_integration(self) -> GithubIntegration:\\n        APP_ID = GITHUB_APP_ID\\n        PRIVATE_KEY = base64.b64decode(GITHUB_APP_PRIVATE_KEY_BASE64).decode(\\\"utf-8\\\")\\n        return GithubIntegration(APP_ID, PRIVATE_KEY)\"}], \"_get_repo_by_url\": [{\"file_path\": \"serverside/src/utils/integrations/github_integration.py\", \"line_start\": 48, \"line_end\": 55, \"content\": \"    def _get_repo_by_url(self, repo_url: str) -> Optional[Repository.Repository]:\\n        installations = self.github_integration.get_installations()\\n\\n        for installation in installations:\\n            for repo in installation.get_repos():\\n                if repo.html_url == repo_url:\\n                    return repo\\n        raise ValueError(f\\\"No matching installation was found for {repo_url}. Maybe the app is not installed yet.\\\")\"}], \"get_installation_by_url\": [{\"file_path\": \"serverside/src/utils/integrations/github_integration.py\", \"line_start\": 57, \"line_end\": 64, \"content\": \"    def get_installation_by_url(self, repo_url: str) -> Optional[Repository.Repository]:\\n        installations = self.github_integration.get_installations()\\n\\n        for installation in installations:\\n            for repo in installation.get_repos():\\n                if repo.html_url == repo_url:\\n                    return installation\\n        raise ValueError(f\\\"No matching installation was found for {repo_url}. Maybe the app is not installed yet.\\\")\"}], \"enrich_callgraph_with_github_context\": [{\"file_path\": \"serverside/src/utils/integrations/github_integration.py\", \"line_start\": 66, \"line_end\": 72, \"content\": \"    def enrich_callgraph_with_github_context(self, callgraph: CallGraph) -> None:\\n        for node_id in callgraph.graph.nodes:\\n            node = callgraph.graph.nodes[node_id]\\n            if \\\"function\\\" in node:\\n                enriched_node = self.enrich_node_with_github_data(node)\\n                if enriched_node:\\n                    callgraph.graph.nodes[node_id].update(enriched_node)\"}], \"_build_index\": [{\"file_path\": \"serverside/src/utils/integrations/github_integration.py\", \"line_start\": 74, \"line_end\": 83, \"content\": \"    def _build_index(self) -> Dict[str, Dict[str, List[Dict[str, Any]]]]:\\n        index = {\\\"class\\\": {}, \\\"function\\\": {}}\\n        contents = self.gh_repo.get_contents(\\\"\\\")\\n        while contents:\\n            file_content = contents.pop(0)\\n            if file_content.type == \\\"dir\\\":\\n                contents.extend(self.gh_repo.get_contents(file_content.path))\\n            elif file_content.name.endswith(\\\".py\\\"):\\n                self._process_python_file(file_content, index)\\n        return index\"}], \"_process_python_file\": [{\"file_path\": \"serverside/src/utils/integrations/github_integration.py\", \"line_start\": 85, \"line_end\": 108, \"content\": \"    def _process_python_file(self, file_content, index) -> None:\\n        try:\\n            file_data = file_content.decoded_content.decode(\\\"utf-8\\\")\\n            tree = ast.parse(file_data, filename=file_content.path)\\n            visitor = DefinitionVisitor()\\n            visitor.visit(tree)\\n            for symbol_type, node in visitor.definitions:\\n                symbol_name = node.name\\n                if symbol_name not in index[symbol_type]:\\n                    index[symbol_type][symbol_name] = []\\n                index[symbol_type][symbol_name].append(\\n                    {\\n                        \\\"file_path\\\": file_content.path,\\n                        \\\"line_start\\\": node.lineno,\\n                        \\\"line_end\\\": (node.end_lineno if hasattr(node, \\\"end_lineno\\\") else node.lineno),\\n                        \\\"content\\\": \\\"\\\\n\\\".join(\\n                            file_data.splitlines()[\\n                                node.lineno - 1 : (node.end_lineno if hasattr(node, \\\"end_lineno\\\") else node.lineno)\\n                            ]\\n                        ),\\n                    }\\n                )\\n        except Exception as e:\\n            logger.exception(f\\\"Error processing {file_content.path}: {e}\\\")\"}], \"lookup_index\": [{\"file_path\": \"serverside/src/utils/integrations/github_integration.py\", \"line_start\": 110, \"line_end\": 111, \"content\": \"    def lookup_index(self, symbol_name: str, symbol_type: str) -> Optional[Dict[str, Any]]:\\n        return self.index.get(symbol_type, {}).get(symbol_name)\"}], \"enrich_node_with_github_data\": [{\"file_path\": \"serverside/src/utils/integrations/github_integration.py\", \"line_start\": 113, \"line_end\": 153, \"content\": \"    def enrich_node_with_github_data(self, node):\\n        \\\"\\\"\\\"\\n        Enriches node attributes with:\\n            - file path from GitHub\\n            - function implementation from GitHub (start_line, end_line, content)\\n            - whole file content from GitHub\\n        \\\"\\\"\\\"\\n        symbol_name = node[\\\"function\\\"]\\n        symbol_type = \\\"function\\\"  # Assuming all nodes in the graph are functions for simplification\\n\\n        # Use the lookup_index method to find the function in the index\\n        defs = self.lookup_index(symbol_name, symbol_type)\\n\\n        if not defs:\\n            node[\\\"github_file_path\\\"] = \\\"not_found\\\"\\n            node[\\\"github_function_implementation\\\"] = \\\"not_found\\\"\\n            node[\\\"github_file_content\\\"] = \\\"not_found\\\"\\n            return\\n\\n        # For simplicity, take the first definition (if multiple are found, this may need refinement)\\n        def_info = defs[0]\\n\\n        # Load the whole file content\\n        try:\\n            file_content = self.gh_repo.get_contents(def_info[\\\"file_path\\\"]).decoded_content.decode(\\\"utf-8\\\")\\n        except Exception as e:\\n            logger.exception(f\\\"Error fetching file content for {def_info['file_path']}: {e}\\\")\\n            file_content = \\\"Error loading file content\\\"\\n\\n        # Update the node with GitHub data\\n        node.update(\\n            {\\n                \\\"github_file_path\\\": def_info[\\\"file_path\\\"],\\n                \\\"github_function_implementation\\\": {\\n                    \\\"start_line\\\": def_info[\\\"line_start\\\"],\\n                    \\\"end_line\\\": def_info[\\\"line_end\\\"],\\n                    \\\"content\\\": def_info[\\\"content\\\"],\\n                },\\n                \\\"github_file_content\\\": file_content,\\n            }\\n        )\"}], \"create_pull_request_with_new_function\": [{\"file_path\": \"serverside/src/utils/integrations/github_integration.py\", \"line_start\": 155, \"line_end\": 227, \"content\": \"    def create_pull_request_with_new_function(\\n        self,\\n        node,\\n        exception_context: Dict[str, Any],\\n        new_implementation: str,\\n        change_reasoning: str,\\n        gpt_helper: OpenAIHelper,\\n    ):\\n        \\\"\\\"\\\"\\n        Update the implementation of a specific function based on node information,\\n        commit the changes to a new branch, and create a pull request with enhanced\\n        context including the exception chain.\\n\\n        Args:\\n            node: The graph node representing the function to be updated.\\n            new_implementation: The new source code for the function.\\n            gpt_helper: An instance of OpenAIHelper for any additional GPT-based processing.\\n            exception_chain: A list of dictionaries, each representing a node in the\\n                            exception chain. Each dictionary should contain at least\\n                            'function_name', 'file_line', and 'exception_info'.\\n        \\\"\\\"\\\"\\n        file_path = node[\\\"github_file_path\\\"]\\n        function_name = node[\\\"function\\\"]\\n        start_line = node[\\\"github_function_implementation\\\"][\\\"start_line\\\"]\\n        end_line = node[\\\"github_function_implementation\\\"][\\\"end_line\\\"]\\n        content = self.gh_repo.get_contents(file_path, ref=\\\"main\\\")\\n        source_code_lines = content.decoded_content.decode(\\\"utf-8\\\").splitlines()\\n\\n        # Replace old function implementation with new content within the source code lines\\n        new_code_lines = (\\n            source_code_lines[: start_line - 1] + new_implementation.splitlines() + source_code_lines[end_line:]\\n        )\\n        updated_source_code = \\\"\\\\n\\\".join(new_code_lines)\\n\\n        fix_styles_query = gpt_helper.generate_after_insert_style_query(updated_source_code, function_name)\\n        updated_source_code = gpt_helper.extract_first_code_block(gpt_helper.call_chatgpt(fix_styles_query))\\n\\n        # Create a new branch for this update\\n        new_branch_name = f\\\"update-{function_name}-{uuid.uuid4().hex}\\\"\\n        base_sha = self.gh_repo.get_branch(\\\"main\\\").commit.sha\\n        self.gh_repo.create_git_ref(ref=f\\\"refs/heads/{new_branch_name}\\\", sha=base_sha)\\n\\n        # Commit the updated file to the new branch\\n        commit_message = f\\\"Update implementation of {function_name}\\\"\\n        self.gh_repo.update_file(\\n            file_path,\\n            commit_message,\\n            updated_source_code,\\n            content.sha,\\n            branch=new_branch_name,\\n        )\\n\\n        # Create a pull request from the new branch to the main branch\\n        pr_title = f\\\"Improve {function_name} implementation\\\"\\n\\n        # Format the exception context for inclusion in the PR body.\\n        exception_context_md = \\\"### Detailed Exception Context\\\\n\\\\n\\\"\\n        for exception_node in exception_context[\\\"exception_nodes\\\"]:\\n            node_details = exception_node[\\\"node_details\\\"]\\n            exception_info = node_details.get(\\\"exception_info\\\", {})\\n            exception_context_md += (\\n                f\\\"- **Function**: {node_details['function_name']} at `{node_details['file_line']}`\\\\n\\\"\\n            )\\n            exception_context_md += f\\\"  - **Exception Type**: {exception_info.get('type')}\\\\n\\\"\\n            exception_context_md += f\\\"  - **Exception Value**: {exception_info.get('value')}\\\\n\\\"\\n            exception_context_md += \\\"\\\\n\\\"\\n\\n        change_reasoning_md = f\\\"### Change Reasoning\\\\n\\\\n{change_reasoning}\\\"\\n\\n        pr_body = f\\\"\\\"\\\"This pull request updates the implementation of `{node[\\\"function\\\"]}` to address the identified issues. Below is the context and reasoning behind these changes.\\\\n\\\\n{exception_context_md}\\\\n\\\\n{change_reasoning_md}\\\\n\\\\n```\\\"\\\"\\\"\\n\\n        pr = self.gh_repo.create_pull(title=pr_title, body=pr_body, head=new_branch_name, base=\\\"main\\\")\\n        logger.info(f\\\"Pull request created: {pr.html_url}\\\")\"}], \"create_pull_request_with_test\": [{\"file_path\": \"serverside/src/utils/integrations/github_integration.py\", \"line_start\": 229, \"line_end\": 255, \"content\": \"    def create_pull_request_with_test(self, test_file_name: str, test_code: str, branch_name_suffix: str):\\n        \\\"\\\"\\\"\\n        Creates a new pull request with a new test file in the 'captureflow_tests/' directory.\\n\\n        Args:\\n            test_file_name (str): The name of the test file to create.\\n            test_code (str): The source code of the test.\\n            branch_name_suffix (str): A suffix for the branch name to ensure it is unique.\\n        \\\"\\\"\\\"\\n        # Define the path where the test file will be stored\\n        test_file_path = f\\\"captureflow_tests/{test_file_name}\\\"\\n\\n        # Create a new branch for this update\\n        new_branch_name = f\\\"add-test-{branch_name_suffix}-{uuid.uuid4().hex}\\\"\\n        base_sha = self.gh_repo.get_branch(\\\"main\\\").commit.sha\\n        self.gh_repo.create_git_ref(ref=f\\\"refs/heads/{new_branch_name}\\\", sha=base_sha)\\n\\n        # Create the test file on the new branch\\n        commit_message = f\\\"Add new test for {test_file_name}\\\"\\n        self.gh_repo.create_file(test_file_path, commit_message, test_code, branch=new_branch_name)\\n\\n        # Create a pull request from the new branch to the main branch\\n        pr_title = f\\\"Add new test for {test_file_name}\\\"\\n        pr_body = \\\"This pull request adds a new test file to improve the test coverage of the repository.\\\"\\n\\n        pr = self.gh_repo.create_pull(title=pr_title, body=pr_body, head=new_branch_name, base=\\\"main\\\")\\n        logger.info(f\\\"Pull request created: {pr.html_url}\\\")\"}], \"_create_openai_client\": [{\"file_path\": \"serverside/src/utils/integrations/openai_integration.py\", \"line_start\": 18, \"line_end\": 19, \"content\": \"    def _create_openai_client(self) -> OpenAI:\\n        return OpenAI(api_key=OPENAI_KEY)\"}], \"generate_initial_scoring_query\": [{\"file_path\": \"serverside/src/utils/integrations/openai_integration.py\", \"line_start\": 21, \"line_end\": 39, \"content\": \"    def generate_initial_scoring_query(self, node) -> str:\\n        cur_fun_name = node[\\\"function\\\"]\\n        cur_fun_impl = node[\\\"github_function_implementation\\\"]\\n        cur_file_impl = node[\\\"github_file_content\\\"]\\n\\n        query = f\\\"\\\"\\\"\\n            Imagine that you're the most competent programmer in San Francisco.\\n            You are tasked with making very safe update to a FUNCTION (not anything else), \\n            but you can improve readability/logic if you're 100% function will do exactly the same thing.\\n\\n            target_function: {cur_fun_name}\\n            function_code: {cur_fun_impl}\\n\\n            whole file code for context: ```{cur_file_impl}```\\n\\n            Please output JSON structuring your view on the question. It needs to have two fields: \\\"quality_score\\\" how much would you rate quality of this function from 1 to 10 and \\\"easy_to_optimize\\\" to label that takes values \\\"EASY_TO_OPTIMIZE\\\", \\\"MAYBE_OPTIMIZE\\\", \\\"HARD_OPTIMIZE\\\" representing if there is a safe refactoring available.\\n        \\\"\\\"\\\"\\n\\n        return query\"}], \"generate_improvement_query\": [{\"file_path\": \"serverside/src/utils/integrations/openai_integration.py\", \"line_start\": 41, \"line_end\": 70, \"content\": \"    def generate_improvement_query(self, call_graph, node) -> str:\\n        # Extract the required details from the log data\\n        cur_fun_name = node[\\\"function\\\"]\\n        cur_fun_path = node[\\\"github_file_path\\\"]\\n        cur_fun_impl = node[\\\"github_function_implementation\\\"]\\n        cur_fun_input = node[\\\"arguments\\\"]\\n        cur_fun_output = node[\\\"return_value\\\"]\\n        cur_file_impl = node[\\\"github_file_content\\\"]\\n\\n        # parent_nodes = list(call_graph.graph.predecessors(node_id))\\n        # children = list(call_graph.graph.successors(node_id))\\n\\n        query = f\\\"\\\"\\\"\\n            Imagine that you're the most competent programmer in San Francisco.\\n            You are tasked with making very safe update to a FUNCTION (not anything else), \\n            but you can improve readability/logic if you're 100% function will do exactly the same thing.\\n\\n            How function is actually implemented: \\n\\n            path: {cur_fun_path}, target_function: {cur_fun_name}\\n            function_code: {cur_fun_impl}\\n            example input: {cur_fun_input}\\n            example output: {cur_fun_output}\\n\\n            whole file code for context: ```{cur_file_impl}```\\n\\n            Please output only single thing, the proposed code of the same function. You can also leave comment in it, asking for for follow-ups.\\n        \\\"\\\"\\\"\\n\\n        return query\"}], \"generate_simulation_query\": [{\"file_path\": \"serverside/src/utils/integrations/openai_integration.py\", \"line_start\": 72, \"line_end\": 129, \"content\": \"    def generate_simulation_query(self, call_graph, node) -> str:\\n        # Extract the required details from the log data\\n        cur_fun_name = node[\\\"function\\\"]\\n        cur_fun_path = node[\\\"github_file_path\\\"]\\n        cur_fun_impl = (\\n            node[\\\"github_function_implementation\\\"][\\\"content\\\"]\\n            if \\\"github_function_implementation\\\" in node\\n            else \\\"Function implementation not found.\\\"\\n        )\\n        cur_fun_input = json.dumps(node.get(\\\"input_value\\\", {}), indent=2)\\n        cur_fun_output = json.dumps(node.get(\\\"return_value\\\", {}), indent=2)\\n        cur_file_impl = node[\\\"github_file_content\\\"]\\n\\n        query = f\\\"\\\"\\\"\\n            As a highly skilled software engineer, you're reviewing a Python function to ensure its correctness and readability. Here's the task:\\n\\n            - File path: {cur_fun_path}\\n            - Target function: {cur_fun_name}\\n\\n            The current implementation of the function is as follows:\\n            ```python\\n            {cur_fun_impl}\\n            ```\\n\\n            Given an example input:\\n            ```\\n            {cur_fun_input}\\n            ```\\n\\n            The function is expected to produce the following output:\\n            ```\\n            {cur_fun_output}\\n            ```\\n\\n            The context of the whole file where the function is located is provided for better understanding:\\n            ```python\\n            {cur_file_impl}\\n            ```\\n\\n            Simulate the environment: Run the improved function with the given example input and compare the output to the expected output.\\n            Finally, provide a confidence level (from 0 to 100%) on whether the improved function will consistently produce the correct output across various inputs, similar to the example provided.\\n            I only need one of three enums in your response \\\"MUST_WORK\\\", \\\"MAYBE_WORK\\\", \\\"DOESNT_WORK\\\". It will show how condident you are new function will function in exactly the same way.\\n            \\n            Also note that inputs and outputs are serialized but probably they're python objects you can deduct from this seralization code\\n            ```python\\n                def _serialize_variable(self, value: Any) -> Dict[str, Any]:\\n                    try:\\n                        json_value = json.dumps(value, default=str)\\n                    except TypeError:\\n                        json_value = str(value)\\n                    return {{\\n                        \\\"python_type\\\": str(type(value)),\\n                        \\\"json_serialized\\\": json_value\\n                    }}\\n            ```\\n        \\\"\\\"\\\"\\n\\n        return query.strip()\"}], \"generate_after_insert_style_query\": [{\"file_path\": \"serverside/src/utils/integrations/openai_integration.py\", \"line_start\": 131, \"line_end\": 140, \"content\": \"    def generate_after_insert_style_query(self, new_file_code, function_name) -> str:\\n        query = f\\\"\\\"\\\"\\n            I have programatically changed source code of my file attempting to rewrite function called {function_name}.\\n            Important: I will give you source code of a file that contains this function, please make sure it aligns well with files (style, tabs, etc).\\n            Do nothing more and give me whole new script (even if nothing needs to be changed)!\\n            \\n            Here's script text: {new_file_code}\\n        \\\"\\\"\\\"\\n\\n        return query.strip()\"}], \"call_chatgpt\": [{\"file_path\": \"serverside/src/utils/integrations/openai_integration.py\", \"line_start\": 142, \"line_end\": 156, \"content\": \"    def call_chatgpt(self, query: str) -> str:\\n        chat_completion = self.client.chat.completions.create(\\n            messages=[\\n                {\\n                    \\\"role\\\": \\\"user\\\",\\n                    \\\"content\\\": query,\\n                },\\n                {\\\"role\\\": \\\"system\\\", \\\"content\\\": \\\"You are a helpful assistant.\\\"},\\n            ],\\n            model=\\\"gpt-4\\\",\\n        )\\n\\n        assert len(chat_completion.choices) == 1\\n\\n        return chat_completion.choices[0].message.content\"}], \"extract_first_code_block\": [{\"file_path\": \"serverside/src/utils/integrations/openai_integration.py\", \"line_start\": 159, \"line_end\": 169, \"content\": \"    def extract_first_code_block(text: str) -> Optional[str]:\\n        pattern = r\\\"```(.*?)```\\\"\\n        match = re.search(pattern, text, re.DOTALL)\\n        code = match.group(1)\\n\\n        if match:\\n            code = code.lstrip(\\\"python\\\")\\n            code = code.lstrip(\\\"\\\\n\\\")\\n            return code\\n\\n        return None\"}], \"get_redis_connection\": [{\"file_path\": \"serverside/src/utils/integrations/redis_integration.py\", \"line_start\": 6, \"line_end\": 7, \"content\": \"def get_redis_connection():\\n    return redis.Redis.from_url(REDIS_URL)\"}], \"test_payload\": [{\"file_path\": \"serverside/src/utils/resources/pytest_template.py\", \"line_start\": 18, \"line_end\": 20, \"content\": \"def test_payload():\\n    \\\"\\\"\\\"Dynamically generates test payload data.\\\"\\\"\\\"\\n    return {\\\"user_id\\\": \\\"example_user\\\", \\\"company_id\\\": \\\"example_company\\\", \\\"amount\\\": 150.0}\"}], \"mock_db\": [{\"file_path\": \"serverside/src/utils/resources/pytest_template.py\", \"line_start\": 25, \"line_end\": 30, \"content\": \"def mock_db():\\n    with patch(\\\"sqlite3.connect\\\") as mock_connect:\\n        # Create a cursor object from a connection object\\n        mock_cursor = MagicMock()\\n        mock_connect.return_value.__enter__.return_value.cursor.return_value = mock_cursor\\n        yield mock_cursor\"}], \"test_endpoint_with_db_interaction\": [{\"file_path\": \"serverside/src/utils/resources/pytest_template.py\", \"line_start\": 34, \"line_end\": 56, \"content\": \"def test_endpoint_with_db_interaction(client, test_payload, mock_db):\\n    mock_db.fetchall.return_value = [(50,), (60,), (70,), (80,), (90,)]\\n\\n    response = client.post(\\\"/test_endpoint_path/\\\", json=test_payload)\\n\\n    assert response.status_code == 200\\n    assert response.json() == {\\n        \\\"user_id\\\": test_payload[\\\"user_id\\\"],\\n        \\\"company_id\\\": test_payload[\\\"company_id\\\"],\\n        \\\"amount\\\": test_payload[\\\"amount\\\"],\\n        \\\"score\\\": test_payload[\\\"amount\\\"] / sum([50, 60, 70, 80, 90]),  # Example calculation\\n    }\\n\\n    # That's how you would mock DB interactions\\n    mock_db.execute.assert_called_once_with(\\n        \\\"\\\"\\\"\\n        SELECT amount FROM transactions\\n        WHERE company_id = ?\\n        ORDER BY timestamp DESC\\n        LIMIT 5\\n        \\\"\\\"\\\",\\n        (test_payload[\\\"company_id\\\"],),\\n    )\"}]}, \"fastapi_apps\": [{\"file_path\": \"clientside/tests/test_fastapi_tracer.py\", \"line_start\": 10, \"line_end\": 10}, {\"file_path\": \"serverside/src/server.py\", \"line_start\": 10, \"line_end\": 10}, {\"file_path\": \"clientside/examples/fastapi/server.py\", \"line_start\": 12, \"line_end\": 12}], \"fastapi_endpoints\": [{\"type\": \"get\", \"function\": \"add\", \"file_path\": \"clientside/tests/test_fastapi_tracer.py\", \"line_start\": 20, \"line_end\": 21}, {\"type\": \"get\", \"function\": \"divide\", \"file_path\": \"clientside/tests/test_fastapi_tracer.py\", \"line_start\": 53, \"line_end\": 54}, {\"type\": \"post\", \"function\": \"store_trace_log\", \"file_path\": \"serverside/src/server.py\", \"line_start\": 86, \"line_end\": 91}, {\"type\": \"post\", \"function\": \"generate_bugfix_mr\", \"file_path\": \"serverside/src/server.py\", \"line_start\": 96, \"line_end\": 99}, {\"type\": \"post\", \"function\": \"generate_test_coverage\", \"file_path\": \"serverside/src/server.py\", \"line_start\": 103, \"line_end\": 110}, {\"type\": \"on_event\", \"function\": \"startup_event\", \"file_path\": \"clientside/examples/fastapi/server.py\", \"line_start\": 22, \"line_end\": 24}, {\"type\": \"post\", \"function\": \"score_transaction\", \"file_path\": \"clientside/examples/fastapi/server.py\", \"line_start\": 29, \"line_end\": 48}]}"
    }
}